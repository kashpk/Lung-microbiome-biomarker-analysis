{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9-tq_ofFswx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "import copy\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "\n",
        "#Pre-Processing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "#models\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import tree\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "!pip install xgboost\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#Kernels\n",
        "from sklearn.gaussian_process.kernels import RBF, WhiteKernel,Matern,ExpSineSquared,RationalQuadratic, ConstantKernel as C\n",
        "\n",
        "#Scipy\n",
        "from scipy.spatial import distance\n",
        "import scipy\n",
        "import scipy.optimize as opt\n",
        "from scipy.optimize import differential_evolution\n",
        "from scipy.optimize import basinhopping\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import norm\n",
        "\n",
        "#Pytorch\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "#For plots\n",
        "!pip install kaleido\n",
        "!sudo apt-get install poppler-utils\n",
        "\n",
        "#Optuna\n",
        "!pip install optuna\n",
        "import optuna\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea5cyf8GaZ1-"
      },
      "source": [
        "**Importing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKBiRg9kaIeg"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ihdavjar/Data_For_Biomarker_Analysis.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ja1Oe_NafNY"
      },
      "source": [
        "**Data Preparation for Lefse**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXaCenphaRk3"
      },
      "outputs": [],
      "source": [
        "data_1=pd.read_csv(\"/content/Data_For_Biomarker_Analysis/Main_Data/Otu_Counts.tsv\")\n",
        "data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BOgRQLq11c7"
      },
      "outputs": [],
      "source": [
        "temp_l_cols=list(data_1.columns)\n",
        "num_taxa_non_unique=[]\n",
        "for i in range(1,len(temp_l_cols)-1):\n",
        "  num_taxa_non_unique.append(sum(list(data_1[temp_l_cols[i]])))\n",
        "\n",
        "plt.hist(num_taxa_non_unique)\n",
        "plt.show()\n",
        "\n",
        "num_taxa_non_unique=np.array(num_taxa_non_unique)\n",
        "plt.hist(num_taxa_non_unique[num_taxa_non_unique<8000])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gB8URSapbyMU"
      },
      "outputs": [],
      "source": [
        "org_data=pd.read_csv(\"/content/Data_For_Biomarker_Analysis/Main_Data/Otu_Counts.tsv\")\n",
        "\n",
        "taxonomy_arr=list(org_data[\"taxonomy\"])\n",
        "otu_ids=list(org_data[\"otu_id\"])\n",
        "print(taxonomy_arr)\n",
        "print(otu_ids)\n",
        "\n",
        "#Removing the taxonomy and the otu_ids from the feature table\n",
        "org_data=org_data.drop([\"otu_id\",\"taxonomy\"],axis=1)\n",
        "\n",
        "\n",
        "temp_data=np.array(org_data)\n",
        "temp_otus=[]\n",
        "for i in range(len(temp_data)):\n",
        "  temp_otus.append(\"Otu\"+str(i+1))\n",
        "\n",
        "\n",
        "#Adding the labels to feature table\n",
        "org_data=org_data.T\n",
        "org_data.columns=temp_otus\n",
        "org_data['total_counts']=num_taxa_non_unique\n",
        "\n",
        "print(org_data)\n",
        "\n",
        "temp_data=pd.read_csv(\"/content/Data_For_Biomarker_Analysis/Main_Data/label_data.csv\")\n",
        "temp_data=temp_data.drop(['Unnamed: 0'],axis=1)\n",
        "temp_data_np=np.array(temp_data)\n",
        "\n",
        "print(temp_data)\n",
        "\n",
        "dict_temp={}\n",
        "for i in range(len(temp_data_np)):\n",
        "  if (temp_data_np[i,1]==\"Squamous cell carcinoma\"):\n",
        "    dict_temp[temp_data_np[i,0]]=\"Squamous\"\n",
        "  else:\n",
        "    dict_temp[temp_data_np[i,0]]=temp_data_np[i,1]\n",
        "\n",
        "l_temp_row=list(org_data.index)\n",
        "temp_labels=[]\n",
        "\n",
        "for i in range(len(l_temp_row)):\n",
        "  if (dict_temp[l_temp_row[i]]==\"Adenosquamous carcinoma\"):\n",
        "    org_data.drop([l_temp_row[i]],axis=0,inplace=True)\n",
        "  else:\n",
        "    temp_labels.append(dict_temp[l_temp_row[i]])\n",
        "\n",
        "\n",
        "org_data_np=np.array(org_data)\n",
        "org_data\n",
        "\n",
        "print(len(num_taxa_non_unique))\n",
        "org_data['label']=temp_labels\n",
        "\n",
        "\n",
        "# org_data=org_data[org_data[\"total_counts\"]<7500]\n",
        "\n",
        "org_data.drop([\"total_counts\"],axis=1,inplace=True)\n",
        "org_data.to_csv('complete_otus.csv',index=False)\n",
        "# files.download('complete_otus.csv')\n",
        "\n",
        "org_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hv_Yvmcb_4e"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "org_data_np=np.array(org_data)\n",
        "\n",
        "labels=le.fit_transform(org_data_np[:,len(org_data_np[0])-1])\n",
        "\n",
        "org_data_np[:,len(org_data_np[0])-1]=labels\n",
        "\n",
        "stan_data=pd.DataFrame(org_data_np,columns=org_data.columns,index=org_data.index)\n",
        "stan_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYZ-PyQscC1q"
      },
      "outputs": [],
      "source": [
        "l_cols=taxonomy_arr\n",
        "print(l_cols)\n",
        "print(len(l_cols))\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  print(temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6117OKS8aw8X"
      },
      "source": [
        "**Data With columns as Phylum, Class, Order, Family, Genus**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAnEljtwbVFN"
      },
      "source": [
        "**Phylum Wise Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SzoWxjZbYMQ"
      },
      "outputs": [],
      "source": [
        "phyllum_labels=[]\n",
        "count_no_phyllum=0\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)!=1):\n",
        "    if (temp[1] not in phyllum_labels):\n",
        "      phyllum_labels.append(temp[1])\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)==1):\n",
        "    count_no_phyllum=count_no_phyllum+1\n",
        "\n",
        "print(\"Number of Taxa without the phyllum labels:-\",count_no_phyllum)\n",
        "\n",
        "print(\"No. of distinct phyllum are:-\",len(phyllum_labels))\n",
        "print(phyllum_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPL3TPcZi_3b"
      },
      "outputs": [],
      "source": [
        "numpy_data=np.array(stan_data)\n",
        "print(l_cols)\n",
        "stan_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDKTulKbcKgt"
      },
      "outputs": [],
      "source": [
        "temp_dict={}\n",
        "for i in range(len(phyllum_labels)):\n",
        "  temp_dict[phyllum_labels[i]]=0\n",
        "\n",
        "temp_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blPLHnl1cR8w"
      },
      "outputs": [],
      "source": [
        "temps_arr=[]\n",
        "\n",
        "for i in range(len(numpy_data)):\n",
        "  temp_arr=numpy_data[i,0:len(numpy_data[0])-1].ravel()\n",
        "  new_dict=copy.deepcopy(temp_dict)\n",
        "  for j in range(len(temp_arr)):\n",
        "    temp=l_cols[j]\n",
        "    temp=temp.split(\";\")\n",
        "    if (len(temp)>1):\n",
        "      new_dict[temp[1]]=new_dict[temp[1]]+temp_arr[j]\n",
        "  temps_arr.append(list(new_dict.values()))\n",
        "\n",
        "temps_arr=np.array(temps_arr)\n",
        "\n",
        "temp_columns=list(temp_dict.keys())\n",
        "\n",
        "phylum_data=pd.DataFrame(temps_arr,columns=np.array(temp_columns),index=np.array(stan_data.index))\n",
        "# phylum_data['treatment']=list(stan_data[\"treatment\"])\n",
        "print(temps_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0d6y1t5cVAE"
      },
      "outputs": [],
      "source": [
        "phylum_data.to_csv(\"phylum_data.csv\")\n",
        "phylum_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfa5qsQfd2_U"
      },
      "source": [
        "**Class Wise Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g8OeKIsd9i_"
      },
      "outputs": [],
      "source": [
        "class_labels=[]\n",
        "count_no_class=0\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)>2):\n",
        "    if (temp[2] not in class_labels):\n",
        "      class_labels.append(temp[2])\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)==2):\n",
        "    count_no_class=count_no_class+1\n",
        "\n",
        "print(\"Number of Taxa without the class labels:-\",count_no_class)\n",
        "\n",
        "print(\"No. of distinct class are:-\",len(class_labels))\n",
        "print(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xsoz28Aqe0pd"
      },
      "outputs": [],
      "source": [
        "temp_dict={}\n",
        "for i in range(len(class_labels)):\n",
        "  temp_dict[class_labels[i]]=0\n",
        "\n",
        "temp_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FEKnN-AfGZq"
      },
      "outputs": [],
      "source": [
        "numpy_data=np.array(stan_data)\n",
        "print(l_cols)\n",
        "stan_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83Z6uK3pe-LB"
      },
      "outputs": [],
      "source": [
        "temps_arr=[]\n",
        "\n",
        "for i in range(len(numpy_data)):\n",
        "  temp_arr=numpy_data[i,0:len(numpy_data[0])-1].ravel()\n",
        "  new_dict=copy.deepcopy(temp_dict)\n",
        "  for j in range(len(temp_arr)):\n",
        "    temp=l_cols[j]\n",
        "    temp=temp.split(\";\")\n",
        "    if (len(temp)>2):\n",
        "      new_dict[temp[2]]=new_dict[temp[2]]+temp_arr[j]\n",
        "  temps_arr.append(list(new_dict.values()))\n",
        "\n",
        "temps_arr=np.array(temps_arr)\n",
        "\n",
        "temp_columns=list(temp_dict.keys())\n",
        "\n",
        "class_data=pd.DataFrame(temps_arr,columns=np.array(temp_columns),index=np.array(stan_data.index))\n",
        "# phylum_data['treatment']=list(stan_data[\"treatment\"])\n",
        "print(temps_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBKy7jSqfghx"
      },
      "outputs": [],
      "source": [
        "class_data.to_csv(\"class_data.csv\")\n",
        "class_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApS4dt49fkTI"
      },
      "source": [
        "**Order Wise Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10I1zuDSf0xz"
      },
      "outputs": [],
      "source": [
        "order_labels=[]\n",
        "count_no_order=0\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)>3):\n",
        "    if (temp[3] not in order_labels):\n",
        "      order_labels.append(temp[3])\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)==3):\n",
        "    count_no_order=count_no_order+1\n",
        "\n",
        "print(\"Number of Taxa without the order labels:-\",count_no_order)\n",
        "\n",
        "print(\"No. of distinct order are:-\",len(order_labels))\n",
        "print(order_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gNQh9FBgEkW"
      },
      "outputs": [],
      "source": [
        "temp_dict={}\n",
        "for i in range(len(order_labels)):\n",
        "  temp_dict[order_labels[i]]=0\n",
        "\n",
        "temp_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fY66x96gHb8"
      },
      "outputs": [],
      "source": [
        "numpy_data=np.array(stan_data)\n",
        "print(l_cols)\n",
        "stan_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOZUbr2ggKY5"
      },
      "outputs": [],
      "source": [
        "temps_arr=[]\n",
        "\n",
        "for i in range(len(numpy_data)):\n",
        "  temp_arr=numpy_data[i,0:len(numpy_data[0])-1].ravel()\n",
        "  new_dict=copy.deepcopy(temp_dict)\n",
        "  for j in range(len(temp_arr)):\n",
        "    temp=l_cols[j]\n",
        "    temp=temp.split(\";\")\n",
        "    if (len(temp)>3):\n",
        "      new_dict[temp[3]]=new_dict[temp[3]]+temp_arr[j]\n",
        "  temps_arr.append(list(new_dict.values()))\n",
        "\n",
        "temps_arr=np.array(temps_arr)\n",
        "\n",
        "temp_columns=list(temp_dict.keys())\n",
        "\n",
        "order_data=pd.DataFrame(temps_arr,columns=np.array(temp_columns),index=np.array(stan_data.index))\n",
        "# phylum_data['treatment']=list(stan_data[\"treatment\"])\n",
        "print(temps_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPx9N1eQgehL"
      },
      "outputs": [],
      "source": [
        "order_data.to_csv(\"order_data.csv\")\n",
        "order_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKqal9mPgk6P"
      },
      "source": [
        "**Family Wise Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuR1_JNIgzGF"
      },
      "outputs": [],
      "source": [
        "family_labels=[]\n",
        "count_no_family=0\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)>4):\n",
        "    if (temp[4] not in family_labels):\n",
        "      family_labels.append(temp[4])\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)==4):\n",
        "    count_no_family=count_no_family+1\n",
        "\n",
        "print(\"Number of Taxa without the order labels:-\",count_no_family)\n",
        "\n",
        "print(\"No. of distinct order are:-\",len(family_labels))\n",
        "print(family_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQWLgoKqhC4D"
      },
      "outputs": [],
      "source": [
        "temp_dict={}\n",
        "for i in range(len(family_labels)):\n",
        "  temp_dict[family_labels[i]]=0\n",
        "\n",
        "temp_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztxU1gL2hTAm"
      },
      "outputs": [],
      "source": [
        "numpy_data=np.array(stan_data)\n",
        "print(l_cols)\n",
        "stan_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PffYI6jPha21"
      },
      "outputs": [],
      "source": [
        "temps_arr=[]\n",
        "\n",
        "for i in range(len(numpy_data)):\n",
        "  temp_arr=numpy_data[i,0:len(numpy_data[0])-1].ravel()\n",
        "  new_dict=copy.deepcopy(temp_dict)\n",
        "  for j in range(len(temp_arr)):\n",
        "    temp=l_cols[j]\n",
        "    temp=temp.split(\";\")\n",
        "    if (len(temp)>4):\n",
        "      new_dict[temp[4]]=new_dict[temp[4]]+temp_arr[j]\n",
        "  temps_arr.append(list(new_dict.values()))\n",
        "\n",
        "temps_arr=np.array(temps_arr)\n",
        "\n",
        "temp_columns=list(temp_dict.keys())\n",
        "\n",
        "family_data=pd.DataFrame(temps_arr,columns=np.array(temp_columns),index=np.array(stan_data.index))\n",
        "# phylum_data['treatment']=list(stan_data[\"treatment\"])\n",
        "print(temps_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv8wVJNyhisx"
      },
      "outputs": [],
      "source": [
        "family_data.to_csv(\"family_data.csv\")\n",
        "family_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37UpLQVehlzp"
      },
      "source": [
        "**Genus Wise Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okePVzSuhuph"
      },
      "outputs": [],
      "source": [
        "genus_labels=[]\n",
        "count_no_genus=0\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)>5):\n",
        "    if (temp[5] not in genus_labels):\n",
        "      genus_labels.append(temp[5])\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)==5):\n",
        "    count_no_genus=count_no_genus+1\n",
        "\n",
        "print(\"Number of Taxa without the order labels:-\",count_no_genus)\n",
        "\n",
        "print(\"No. of distinct order are:-\",len(genus_labels))\n",
        "print(genus_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OBoMwrEiF5L"
      },
      "outputs": [],
      "source": [
        "temp_dict={}\n",
        "for i in range(len(genus_labels)):\n",
        "  temp_dict[genus_labels[i]]=0\n",
        "\n",
        "temp_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpYq3BlriMxK"
      },
      "outputs": [],
      "source": [
        "numpy_data=np.array(stan_data)\n",
        "print(l_cols)\n",
        "stan_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT457j7EiShM"
      },
      "outputs": [],
      "source": [
        "temps_arr=[]\n",
        "\n",
        "for i in range(len(numpy_data)):\n",
        "  temp_arr=numpy_data[i,0:len(numpy_data[0])-1].ravel()\n",
        "  new_dict=copy.deepcopy(temp_dict)\n",
        "  for j in range(len(temp_arr)):\n",
        "    temp=l_cols[j]\n",
        "    temp=temp.split(\";\")\n",
        "    if (len(temp)>5):\n",
        "      new_dict[temp[5]]=new_dict[temp[5]]+temp_arr[j]\n",
        "  temps_arr.append(list(new_dict.values()))\n",
        "\n",
        "temps_arr=np.array(temps_arr)\n",
        "\n",
        "temp_columns=list(temp_dict.keys())\n",
        "\n",
        "genus_data=pd.DataFrame(temps_arr,columns=np.array(temp_columns),index=np.array(stan_data.index))\n",
        "# phylum_data['treatment']=list(stan_data[\"treatment\"])\n",
        "print(temps_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4hWBtn4iji2"
      },
      "outputs": [],
      "source": [
        "genus_data.to_csv(\"genus_data.csv\")\n",
        "genus_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOKtBQn8cvEg"
      },
      "source": [
        "**Checking the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1Qt446fQxOT"
      },
      "outputs": [],
      "source": [
        "temp_all_data=[]\n",
        "for i in range(len(numpy_data)):\n",
        "  temp_all_data.append(sum(numpy_data[i,:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAlFHDi7QMeQ"
      },
      "outputs": [],
      "source": [
        "genus_data_np=np.array(genus_data)\n",
        "\n",
        "temp_genus_data=[]\n",
        "for i in range(len(genus_data_np)):\n",
        "  temp_genus_data.append(sum(genus_data_np[i,:]))\n",
        "\n",
        "\n",
        "print(temp_all_data)\n",
        "print(temp_genus_data)\n",
        "\n",
        "for i in range(len(temp_all_data)):\n",
        "  if (temp_all_data[i]<temp_genus_data[i]):\n",
        "    print(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPqUHoHMipAu"
      },
      "source": [
        "**Combining all the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShWI--d9iv6y"
      },
      "outputs": [],
      "source": [
        "phylum_data_np=np.array(phylum_data)\n",
        "class_data_np=np.array(class_data)\n",
        "order_data_np=np.array(order_data)\n",
        "family_data_np=np.array(family_data)\n",
        "genus_data_np=np.array(genus_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeP6sqe5jqwy"
      },
      "outputs": [],
      "source": [
        "temp_data=np.c_[phylum_data_np,class_data_np,order_data_np,family_data_np,genus_data_np]\n",
        "\n",
        "print(np.shape(temp_data))\n",
        "\n",
        "comp_data=pd.DataFrame(temp_data,index=phylum_data.index,columns=list(phylum_data.columns)+list(class_data.columns)+list(order_data.columns)+list(family_data.columns)+list(genus_data.columns))\n",
        "# comp_data[\"label\"]=stan_data[\"label\"]\n",
        "comp_data.insert(loc=0, column='label', value=0.01)\n",
        "comp_data.insert(loc=1, column='group', value=list(comp_data.index))\n",
        "comp_data.insert(loc=2, column='count', value=359)\n",
        "\n",
        "comp_data[\"treatment\"]=stan_data['label']\n",
        "comp_data.to_csv(\"comp_data.csv\")\n",
        "comp_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrVe9edIsHsw"
      },
      "source": [
        "**Lefse Plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIppkAbnsJxq"
      },
      "outputs": [],
      "source": [
        "data_1=pd.read_csv(\"/content/Data_For_Biomarker_Analysis/Lefse_Analysis/ALL_Cats/output_ALL_Cats.csv\")\n",
        "data_1.dropna(inplace=True)\n",
        "data_1.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
        "data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9xa412othCS"
      },
      "outputs": [],
      "source": [
        "temp_data=[]\n",
        "data_np=np.array(data_1)\n",
        "temp_labels=[]\n",
        "for i in range(len(data_1)):\n",
        "  if (data_np[i,1]<0):\n",
        "    temp_labels.append(\"Adenocarcinoma\")\n",
        "  else:\n",
        "    temp_labels.append(\"Squamous cell carcinoma\")\n",
        "\n",
        "data_1[\"Class\"]=temp_labels\n",
        "\n",
        "temp_data.append(data_1)\n",
        "data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrVeKPLBttuO"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(data_1, x='scores', y='Names',orientation='h',color=\"Class\",labels=dict(Names=\"\", scores=\"LDA Score\", Class=\"Groups\"))\n",
        "pio.write_image(fig, 'plot_all.svg',scale=7, width=800, height=600)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GAn22nPvvMk"
      },
      "outputs": [],
      "source": [
        "Lda_threshold=0.5\n",
        "# Lda_threshold_1=0.5\n",
        "\n",
        "data_2=data_1[abs(data_1[\"scores\"])>=Lda_threshold]\n",
        "\n",
        "# data_1_temp_1 = data_1[data_1[\"Class\"]==\"Squamous\"]\n",
        "# data_1_temp_1 = data_1_temp_1[abs(data_1_temp_1[\"scores\"])>=Lda_threshold_1]\n",
        "\n",
        "# data_1_temp_2 = data_1[data_1[\"Class\"]==\"Adenocarcinoma\"]\n",
        "# data_1_temp_2 = data_1_temp_2[abs(data_1_temp_2[\"scores\"])>=Lda_threshold]\n",
        "\n",
        "# data_2 = pd.concat([data_1_temp_2,data_1_temp_1],axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Class=\"Lung cancer subtypes\""
      ],
      "metadata": {
        "id": "Ut344kMon4yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.bar(data_2, x='scores', y='Names',orientation='h',color=\"Class\",\n",
        "             hover_name=\"Class\", color_discrete_sequence=[\"magenta\", \"orange\"],\n",
        "             labels=dict(Names=\"\", scores=\"LDA Score\"))\n",
        "\n",
        "#pio.write_image(fig, 'plot_all_2.svg',scale=7, width=600, height=600)\n",
        "\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=700,\n",
        "    height=800,\n",
        "    font_color=\"black\",\n",
        "   )\n",
        "\n",
        "\n",
        "#fig5.update_layout(legend=dict(\n",
        "# orientation=\"h\",entrywidth=85,font=dict(size=8)))\n",
        "fig.show()\n",
        "\n",
        "\n",
        "fig.write_image(\"lefse_otu.pdf\")\n",
        "fig.write_image(\"lefse_otu.svg\")\n",
        "\n",
        "fig.write_image(\"lefse_otu.png\")\n"
      ],
      "metadata": {
        "id": "wLW11Qe8EvlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LNH2WWgUCHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65wM76RF2rOA"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(data_2, x='scores', y='Names',orientation='h',color=\"Class\",labels=dict(Names=\"\", scores=\"LDA Score\", Class=\"Groups\"))\n",
        "pio.write_image(fig, 'plot_all_2.svg',scale=7, width=600, height=600)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59I3S6Alv1AV"
      },
      "outputs": [],
      "source": [
        "temp_arr_names=[]\n",
        "\n",
        "chosen_taxa=list(data_2[\"Names\"])\n",
        "\n",
        "print(\"Number of statistically significant taxa are:-\",len(chosen_taxa))\n",
        "\n",
        "for i in range(len(chosen_taxa)):\n",
        "  if (str(chosen_taxa[i])=='g__0319.6G20'):\n",
        "    temp_arr_names.append(\" g__0319-6G20\")\n",
        "  elif (str(chosen_taxa[i])=='f__0319.6G20'):\n",
        "    temp_arr_names.append(\" f__0319-6G20\")\n",
        "  elif (str(chosen_taxa[i])=='o__0319.6G20'):\n",
        "    temp_arr_names.append(\" o__0319-6G20\")\n",
        "  else:\n",
        "    temp_arr_names.append(\" \"+str(chosen_taxa[i]))\n",
        "\n",
        "print(temp_arr_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9rU0ofqJEGaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_feature_data=comp_data[temp_arr_names]\n",
        "selected_feature_data_copy = copy.deepcopy(selected_feature_data)\n",
        "selected_feature_data\n",
        "font_size=5\n",
        "\n",
        "fig=plt.figure(figsize=(8,8))\n",
        "\n",
        "\n",
        "sns.heatmap(selected_feature_data.corr(),cmap=\"BrBG\",annot=False)\n",
        "\n",
        "\n",
        "#plt.savefig(\"lda_corr_plot.svg\")\n",
        "#plt.savefig(\"lda_corr_plot.png\")\n",
        "#plt.savefig(\"lda_corr_plot.pdf\")"
      ],
      "metadata": {
        "id": "9hZ6yQkHFLV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys-g2y1ayL53"
      },
      "outputs": [],
      "source": [
        "selected_feature_data=comp_data[temp_arr_names]\n",
        "selected_feature_data_copy = copy.deepcopy(selected_feature_data)\n",
        "selected_feature_data\n",
        "\n",
        "# Set the font size for the x and y labels\n",
        "label_font_size = 6  # Change this to your desired font size\n",
        "\n",
        "# Create the heatmap\n",
        "fig = plt.figure(figsize=(7.5, 6.5))\n",
        "ax = sns.heatmap(selected_feature_data.corr(), cmap=\"cividis\", annot=False)\n",
        "\n",
        "# Change the font size of x and y axis labels\n",
        "ax.set_xticklabels(ax.get_xticklabels(), size=label_font_size)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), size=label_font_size)\n",
        "\n",
        "# Show the plot\n",
        "#plt.savefig(\"lda_corr.svg\")\n",
        "plt.show()\n",
        "\n",
        "# Save the plot to an image file with a larger size\n",
        "# Adjust the DPI and format as needed\n",
        "ax.get_figure().savefig(\"heatmap.svg\", dpi=600, bbox_inches='tight', format='svg')\n",
        "ax.get_figure().savefig(\"heatmap.png\", dpi=600, bbox_inches='tight', format='png')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_feature_data.corr()\n"
      ],
      "metadata": {
        "id": "MwR8Ivd-ay69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have already defined your 'selected_feature_data' DataFrame and calculated the correlation matrix\n",
        "correlation_matrix = selected_feature_data.corr()\n",
        "\n",
        "# Save the correlation matrix to an Excel file (in this example, we're using XLSX format)\n",
        "correlation_matrix.to_excel('correlation_matrix.xlsx', sheet_name='Correlation')\n"
      ],
      "metadata": {
        "id": "C29RGqsLvUvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create correlation matrix\n",
        "corr_matrix = selected_feature_data.corr().abs()\n",
        "\n",
        "# Select upper triangle of correlation matrix\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "# Find features with correlation greater than 0.95\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.99)]\n",
        "\n",
        "# Drop features\n",
        "selected_feature_data.drop(to_drop, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "afdzYspOeLmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selected_feature_data.drop([\" g__uncultured\"],axis=1,inplace=True)\n",
        "selected_feature_data[\" g__Thermus\"] = selected_feature_data_copy[\" g__Thermus\"]\n",
        "selected_feature_data"
      ],
      "metadata": {
        "id": "B7D3iFRyeMLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Old columns:-\")\n",
        "print(list(selected_feature_data_copy.columns))\n",
        "print(\"New columns:-\")\n",
        "print(list(selected_feature_data.columns))"
      ],
      "metadata": {
        "id": "F5Ii1iePVG98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoeAs9Ic0isA"
      },
      "source": [
        "**Including Meta Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5inORIz0n-_"
      },
      "outputs": [],
      "source": [
        "meta_data=pd.read_csv(\"/content/Data_For_Biomarker_Analysis/Main_Data/Meta_Data.tsv\",sep='\\t')\n",
        "meta_data.drop([0],axis=0,inplace=True)\n",
        "meta_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMYzcm3BE2qE"
      },
      "source": [
        "**Choosing the important columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQuHCQP6E2ZF"
      },
      "outputs": [],
      "source": [
        "print(meta_data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeEC_jjbFQhL"
      },
      "source": [
        "**Choosing env_material, Host_Age, host_sex, smoker**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUOFgjhRGJbk"
      },
      "outputs": [],
      "source": [
        "# [\" Sample-id\",\"env_material\",\"Host_Age\",\"host_sex\",\"smoker\"]\n",
        "meta_data=meta_data[[\" Sample-id\",\"env_material\",\"Host_Age\",\"host_sex\",\"smoker\"]]\n",
        "meta_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL7MoDl_02my"
      },
      "outputs": [],
      "source": [
        "meta_data_np=np.array(meta_data)\n",
        "print(meta_data_np)\n",
        "\n",
        "temp_sample_dict={}\n",
        "\n",
        "for i in range(len(meta_data_np)):\n",
        "  temp_sample_dict[meta_data_np[i,0]]=meta_data_np[i,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs6F4qIG05BO"
      },
      "outputs": [],
      "source": [
        "temp_sample_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sasRRk3V09R-"
      },
      "outputs": [],
      "source": [
        "temp_sample_names=list(selected_feature_data.index)\n",
        "\n",
        "chosen_meta_data_np=[]\n",
        "\n",
        "for i in range(len(temp_sample_names)):\n",
        "  chosen_meta_data_np.append(temp_sample_dict[temp_sample_names[i]])\n",
        "\n",
        "chosen_meta_data_np=np.array(chosen_meta_data_np)\n",
        "chosen_meta_data_np\n",
        "\n",
        "chosen_meta_data=pd.DataFrame(chosen_meta_data_np,index=temp_sample_names,columns=list(meta_data.columns)[1:])\n",
        "chosen_meta_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mTHgil39dJv"
      },
      "source": [
        "**For the Data Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kf98J8jgq0gZ"
      },
      "outputs": [],
      "source": [
        "stan_data_np=np.array(stan_data)\n",
        "list_sample_names=list(stan_data.index)\n",
        "\n",
        "temp_sample_dict={}\n",
        "\n",
        "for i in range(len(stan_data_np)):\n",
        "  temp_sample_dict[list_sample_names[i]]=stan_data_np[i,len(stan_data_np[0])-1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QV9ptLOwrcEZ"
      },
      "outputs": [],
      "source": [
        "temp_sample_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1vtJP4i3Ayg"
      },
      "source": [
        "**Combining Meta data with taxa data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka0KUmL53EaH"
      },
      "outputs": [],
      "source": [
        "chosen_column1_np=np.array(selected_feature_data)\n",
        "chosen_column2_np=np.array(chosen_meta_data)\n",
        "\n",
        "data=np.array(stan_data)\n",
        "\n",
        "x_data=np.c_[chosen_column1_np,chosen_column2_np]\n",
        "print(np.shape(x_data))\n",
        "\n",
        "\n",
        "result_data=pd.DataFrame(x_data,index=selected_feature_data.index,columns=list(selected_feature_data.columns)+list(chosen_meta_data.columns))\n",
        "\n",
        "temp_na_data = copy.deepcopy(result_data)\n",
        "\n",
        "#For seeing the Na elements\n",
        "list_names_selected_feature_data=list(temp_na_data.index)\n",
        "y_data_temp=[]\n",
        "for i in range(len(list_names_selected_feature_data)):\n",
        "  y_data_temp.append(temp_sample_dict[list_names_selected_feature_data[i]])\n",
        "\n",
        "temp_na_data[\"label\"]=y_data_temp\n",
        "\n",
        "\n",
        "print(temp_na_data[temp_na_data.isnull().any(axis=1)])\n",
        "\n",
        "#Removing The Na\n",
        "result_data.dropna(inplace=True)\n",
        "\n",
        "le1 = preprocessing.LabelEncoder()\n",
        "le2 = preprocessing.LabelEncoder()\n",
        "le3 = preprocessing.LabelEncoder()\n",
        "\n",
        "result_data[\"env_material\"]=le1.fit_transform(result_data[\"env_material\"])\n",
        "result_data[\"host_sex\"]=le2.fit_transform(result_data[\"host_sex\"])\n",
        "result_data[\"smoker\"]=le3.fit_transform(result_data[\"smoker\"])\n",
        "\n",
        "\n",
        "\n",
        "result_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kvuc6mmwgN1b"
      },
      "outputs": [],
      "source": [
        "# temp_arr_taxa=[\" p__Deinococcota\",\" c__Deinococci\",\" o__Thermales\",\" g__Thermus\"]\n",
        "\n",
        "# for i in range(len(temp_arr_taxa)):\n",
        "#   temp=list(result_data[temp_arr_taxa[i]])\n",
        "#   print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfV2RgDuroIL"
      },
      "outputs": [],
      "source": [
        "list_names_selected_feature_data=list(result_data.index)\n",
        "y_data=[]\n",
        "for i in range(len(list_names_selected_feature_data)):\n",
        "  y_data.append(temp_sample_dict[list_names_selected_feature_data[i]])\n",
        "\n",
        "result_data[\"label\"]=y_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFnkB27pcQkC"
      },
      "outputs": [],
      "source": [
        "print(le1.inverse_transform([0,1]))\n",
        "print(le2.inverse_transform([0,1]))\n",
        "print(le3.inverse_transform([0,1,2]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nOR0Wz8aIvb"
      },
      "outputs": [],
      "source": [
        "stan_data_np=np.array(stan_data).astype(int)\n",
        "print(\"Number of features are:-\",len(stan_data_np[0])-1)\n",
        "print(\"Total Number of Instances are:-\",len(+stan_data_np))\n",
        "\n",
        "result_data_np=np.array(result_data).astype(float)\n",
        "print(\"Number of features are:-\",len(result_data_np[0])-1)\n",
        "print(\"Total Number of Instances are:-\",len(result_data_np))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yviRMmPzbefD"
      },
      "outputs": [],
      "source": [
        "print(\"0-->\",le.inverse_transform([0]),\"1-->\",le.inverse_transform([1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS1ehn_9mAiu"
      },
      "outputs": [],
      "source": [
        "stan_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyDg-9l5iDWT"
      },
      "outputs": [],
      "source": [
        "result_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHmg5-31n-xW"
      },
      "source": [
        "**Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzUWiVlrrQm7"
      },
      "outputs": [],
      "source": [
        "org_data['label'].value_counts().plot(kind='pie', autopct = \"%1.0f%%\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNuhbHEFqCNn"
      },
      "source": [
        "**Analysing types**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HahMLPXMoCBi"
      },
      "outputs": [],
      "source": [
        "result_data=result_data.astype(float)\n",
        "result_data_np.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b4kwDIon-jk"
      },
      "outputs": [],
      "source": [
        "stan_data_np.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhhAIRGpqFzo"
      },
      "source": [
        "**Data Description**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMxxtfVrqhK4"
      },
      "outputs": [],
      "source": [
        "def my_df_describe(df):\n",
        "    objects = []\n",
        "    numerics = []\n",
        "    for c in df:\n",
        "        if (df[c].dtype == object):\n",
        "            objects.append(c)\n",
        "        else:\n",
        "            numerics.append(c)\n",
        "\n",
        "    return df[numerics].describe(), df[objects].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRvv60jQrpDx"
      },
      "source": [
        "**Correlation Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5dxHMDBrtA7"
      },
      "outputs": [],
      "source": [
        "temp_data=result_data.astype(int)\n",
        "px.imshow(temp_data.corr())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTRTxzDksnK0"
      },
      "source": [
        "**Outlier Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHDvBYohsprk"
      },
      "outputs": [],
      "source": [
        "# fig = px.box(temp_data,y=' f__Thermaceae',x=\"env_material\",title=f\"Distrubution of Age\")\n",
        "# fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0dT9mGzv1d7"
      },
      "outputs": [],
      "source": [
        "def cat_of_list(l):\n",
        "  l1=[]\n",
        "  for i in l:\n",
        "    if i not in l1:\n",
        "      l1.append(i)\n",
        "  return l1\n",
        "\n",
        "def categories_output(d):\n",
        "  l_col=list(d.columns)\n",
        "  l1=[]\n",
        "  d1={}\n",
        "  for i in l_col:\n",
        "    l=list(d[i])\n",
        "    if (type(l[0])==str):\n",
        "      l1.append(i)\n",
        "      d1[i]=cat_of_list(l)\n",
        "  print(d1)\n",
        "  return d1;\n",
        "\n",
        "def visualisation_bar_hist(data):\n",
        "  l_col=list(data.columns)\n",
        "  temp_cat=categories_output(data)\n",
        "  temp_keys=list(temp_cat.keys())\n",
        "  temp_values=list(temp_cat.values())\n",
        "\n",
        "  for i in range(len(l_col)-1):\n",
        "    if l_col[i] in temp_keys:\n",
        "      label=l_col[i]\n",
        "      temp_val=temp_cat[label]\n",
        "      temp_list=[]\n",
        "      temp_columns=list(data[label])\n",
        "      for j in range(len(temp_val)):\n",
        "        temp_list.append(temp_columns.count(temp_val[j]))\n",
        "\n",
        "      plt.bar(temp_val,temp_list,color='red')\n",
        "      plt.title(l_col[i]+\"-Bar Graph\")\n",
        "      plt.ylabel(\"Frequency\")\n",
        "      plt.show()\n",
        "      print()\n",
        "    else:\n",
        "      temp_columns=list(data[l_col[i]])\n",
        "      sns.histplot(temp_columns,color=\"red\",kde=True)\n",
        "      plt.title(l_col[i])\n",
        "      plt.ylabel(\"Frequency\")\n",
        "      plt.show()\n",
        "      print()\n",
        "\n",
        "# visualisation_bar_hist(result_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ3UMVOdwd1u"
      },
      "outputs": [],
      "source": [
        "l_cols_result_data=list(result_data.columns)[0:len(result_data_np[0])-3]\n",
        "\n",
        "result_data_no_out=copy.deepcopy(result_data)\n",
        "\n",
        "# for i in range(len(l_cols_result_data)):\n",
        "#   temp_=list(result_data_no_out[l_cols_result_data[i]])\n",
        "#   # print(max(temp_))\n",
        "#   result_data_no_out=result_data_no_out[result_data_no_out[l_cols_result_data[i]]<0.95*(max(temp_))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA4GnOH2xKvK"
      },
      "outputs": [],
      "source": [
        "result_data_no_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge30Whqhzi6u"
      },
      "outputs": [],
      "source": [
        "#This function will basically give all the pairs of highly correlated features\n",
        "def find_outliers(cov_data):\n",
        "  l_cols=list(cov_data.columns)\n",
        "  max_cov=-1\n",
        "  in1=0\n",
        "  in2=0\n",
        "  for i in range(len(l_cols)):\n",
        "    temp_l=list(cov_data[l_cols[i]])\n",
        "    for j in range(len(l_cols)):\n",
        "      if (max_cov<abs(temp_l[j]) and i!=j):\n",
        "        in1=i\n",
        "        in2=j\n",
        "\n",
        "  return [l_cols[in1],l_cols[in2]]\n",
        "\n",
        "#This is the x_data in pandas format\n",
        "# x_data_pd=pd.DataFrame(x_data,columns=l_col_new[0:len(l_col_new)-1])\n",
        "x_data_pd=result_data_no_out.drop(['label'],axis=1)\n",
        "\n",
        "temp_outliers=find_outliers(x_data_pd.cov())\n",
        "\n",
        "temp_data=x_data_pd.copy(deep=True)\n",
        "\n",
        "for i in range(1):\n",
        "  temp_outliers=find_outliers(temp_data.cov())\n",
        "  plt.scatter(x_data_pd[temp_outliers[0]],x_data_pd[temp_outliers[1]],color=\"brown\")\n",
        "  plt.xlabel(temp_outliers[0])\n",
        "  plt.ylabel(temp_outliers[1])\n",
        "  temp_data=temp_data.drop([temp_outliers[0],temp_outliers[1]],axis=1)\n",
        "  print(\"\\n\")\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrHFa8Q9aJ5u"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5OhFVU5dNWP"
      },
      "outputs": [],
      "source": [
        "x_data_pd=result_data_no_out.drop(['label'],axis=1)\n",
        "\n",
        "#Normalisation\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "x_data_pd_stan=pd.DataFrame(scaler.fit_transform(x_data_pd),columns=x_data_pd.columns,index=x_data_pd.index)\n",
        "\n",
        "x_data_pd_stan= x_data_pd\n",
        "\n",
        "x_data_pd_stan[\"sample_id\"] = result_data_no_out.index\n",
        "\n",
        "x_data_pd['label']=result_data['label']\n",
        "\n",
        "x_data_pd_stan['label']=result_data['label']\n",
        "\n",
        "\n",
        "result_data=x_data_pd_stan\n",
        "\n",
        "\n",
        "result_data_class0=result_data[result_data[\"label\"]==0]\n",
        "result_data_class1=result_data[result_data[\"label\"]==1]\n",
        "\n",
        "result_data_class_0_np=np.array(result_data_class0)\n",
        "result_data_class_1_np=np.array(result_data_class1)\n",
        "\n",
        "print(np.unique(result_data_class_0_np[:,len(result_data_class_0_np[0])-1]))\n",
        "print(np.unique(result_data_class_1_np[:,len(result_data_class_1_np[0])-1]))\n",
        "\n",
        "x_class_0=result_data_class_0_np[:,0:len(result_data_class_0_np[0])-1]\n",
        "y_class_0=result_data_class_0_np[:,len(result_data_class_0_np[0])-1].astype(int)\n",
        "\n",
        "x_class_1=result_data_class_1_np[:,0:len(result_data_class_1_np[0])-1]\n",
        "y_class_1=result_data_class_1_np[:,len(result_data_class_1_np[0])-1].astype(int)\n",
        "\n",
        "#CLASS 0\n",
        "x_train_0, x_test_0, y_train_0, y_test_0 = train_test_split(x_class_0, y_class_0, test_size=0.3,shuffle=True, random_state=42)\n",
        "\n",
        "#CLASS 1\n",
        "x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(x_class_1, y_class_1, test_size=0.3,shuffle=True, random_state=42)\n",
        "\n",
        "#Train Data\n",
        "x_train=np.r_[x_train_0,x_train_1]\n",
        "y_train=np.r_[y_train_0,y_train_1]\n",
        "\n",
        "sample_id_train = x_train[:,len(x_train[0])-1]\n",
        "\n",
        "x_train = x_train[:,:len(x_train[0])-1].astype(float)\n",
        "\n",
        "\n",
        "\n",
        "#Test Data\n",
        "x_test=np.r_[x_test_0,x_test_1]\n",
        "y_test=np.r_[y_test_0,y_test_1]\n",
        "\n",
        "sample_id_test = x_test[:,len(x_test[0])-1]\n",
        "\n",
        "x_test = x_test[:,:len(x_test[0])-1].astype(float)\n",
        "\n",
        "\n",
        "print(\"Number of Instances in Training Data of class 0:-\",len(x_train_0))\n",
        "print(\"Number of Instances in Training Data of class 1:-\",len(x_train_1))\n",
        "\n",
        "print(\"Number of Instances in Testing Data of class 0:-\",len(x_test_0))\n",
        "print(\"Number of Instances in Testing Data of class 1:-\",len(x_test_1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying LDA to the DATA**"
      ],
      "metadata": {
        "id": "VAxBKOaeCj5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda =LinearDiscriminantAnalysis().fit(x_train,y_train)\n",
        "\n",
        "x_train = lda.transform(x_train)\n",
        "x_test = lda.transform(x_test)"
      ],
      "metadata": {
        "id": "9fvNXY8uCmOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "3UAn2pbxS04-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x_train,y_train.reshape(-1,1),c=y_train.reshape(-1,1))\n",
        "plt.savefig(\"lda_plot.pdf\",dpi=1200)\n",
        "plt.savefig(\"lda_plot.svg\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6NmS7qakDYjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x_train[y_train==0],y_train.reshape(-1,1)[y_train==0],c='magenta',label=\"AC\")\n",
        "plt.scatter(x_train[y_train==1],y_train.reshape(-1,1)[y_train==1],c='orange',label=\"SCC\")\n",
        "plt.legend()\n",
        "#plt.ylabel(\"Class Label\")\n",
        "plt.savefig(\"lda_before.pdf\",dpi=1200)\n",
        "plt.savefig(\"lda_before.svg\")\n",
        "plt.savefig(\"lda_before.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oJmPKwUqPFvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x_train,np.zeros((len(x_train),1)),c=y_train.reshape(-1,1),alpha=0.5)\n",
        "plt.savefig(\"lda_after.svg\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yc4fMBPUEdez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x_train[y_train==0],np.zeros((len(x_train[y_train==0]),1)),c='magenta',label=\"AC\")\n",
        "plt.scatter(x_train[y_train==1],np.zeros((len(x_train[y_train==1]),1)),c='orange',label=\"SCC\")\n",
        "plt.legend()\n",
        "plt.savefig(\"lda_after.pdf\",dpi=1200)\n",
        "plt.savefig(\"lda_after.svg\")\n",
        "plt.savefig(\"lda_after.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w78rz8EXPk2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_0_train_samples = x_train[y_train==0]\n",
        "class_1_train_samples = x_train[y_train==1]\n",
        "\n",
        "\n",
        "sns.histplot({'AC': class_0_train_samples.ravel(), 'SCC': class_1_train_samples.ravel()}, bins=70, palette=['magenta', 'orange'], kde=True, stat='density')\n",
        "plt.savefig(\"lda hist.png\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "PLVdO-MzEwuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSz361FW_DUq"
      },
      "source": [
        "**Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlM5FHi1_UNh"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN7uxtRFGd5f"
      },
      "outputs": [],
      "source": [
        "model_lr = LogisticRegression(random_state=0).fit(x_train,y_train)\n",
        "y_pred_lr=model_lr.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy is:-\",model_lr.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_lr.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLzaTvCyY1Bi"
      },
      "outputs": [],
      "source": [
        "temp_arr=model_lr.coef_\n",
        "print(temp_arr)\n",
        "temp_arr.sort()\n",
        "temp_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mh26W54PJrhb"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_lr, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x20ps2sRIyiB"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_lr,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2rbVwgnKkIV"
      },
      "outputs": [],
      "source": [
        "probs = model_lr.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt2QNVEeLKBw"
      },
      "source": [
        "**Gaussian Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Le5lB1bLat4"
      },
      "outputs": [],
      "source": [
        "model_nb = GaussianNB().fit(x_train,y_train)\n",
        "y_pred_nb=model_nb.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy is:-\",model_nb.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_nb.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYNnduU6Lat5"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_nb, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPg_jgqULat5"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_nb,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWijAPCxLat5"
      },
      "outputs": [],
      "source": [
        "probs = model_nb.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=5)"
      ],
      "metadata": {
        "id": "Om7CGvJiAIu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1A6N3MZ6H"
      },
      "source": [
        "**Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "  temp_acc = []\n",
        "\n",
        "  max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
        "\n",
        "  min_samples_split = trial.suggest_int(\"min_samples_split\",2,50)\n",
        "\n",
        "  min_samples_leaf = trial.suggest_int(\"min_samples_leaf\",1,50)\n",
        "\n",
        "  max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\",5,100)\n",
        "\n",
        "  #K-fold stratified Split\n",
        "  for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
        "    y_train_temp = y_train[train_index]\n",
        "    x_train_temp = x_train[train_index]\n",
        "\n",
        "    y_val_temp = y_train[test_index]\n",
        "    x_val_temp = x_train[test_index]\n",
        "\n",
        "    model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, max_leaf_nodes = max_leaf_nodes,random_state=42)\n",
        "\n",
        "    #Training the Model\n",
        "    model.fit(x_train_temp,y_train_temp.ravel())\n",
        "\n",
        "    y_pred = model.predict(x_val_temp)\n",
        "\n",
        "    v0 = metrics.accuracy_score(y_val_temp, y_pred)\n",
        "\n",
        "    if (len(temp_data_np)==0):\n",
        "      v0 = 0\n",
        "\n",
        "    temp_acc.append(v0)\n",
        "\n",
        "  return np.array(temp_acc).mean()\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "print(study.best_params)\n"
      ],
      "metadata": {
        "id": "Kh686w4O8aVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = study.best_params"
      ],
      "metadata": {
        "id": "Se9mmEU0-AGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = temp_dict[\"max_depth\"]\n",
        "\n",
        "min_samples_split = temp_dict[\"min_samples_split\"]\n",
        "\n",
        "min_samples_leaf = temp_dict[\"min_samples_leaf\"]\n",
        "\n",
        "max_leaf_nodes = temp_dict[\"max_leaf_nodes\"]"
      ],
      "metadata": {
        "id": "3o1QG1Ux90wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCmhD6ENNcYa"
      },
      "outputs": [],
      "source": [
        "model_dc = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, max_leaf_nodes = max_leaf_nodes,random_state=42).fit(x_train,y_train)\n",
        "y_pred_dc=model_dc.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy is:-\",model_dc.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_dc.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frZ2VpgeNcYa"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_dc, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvXc-alqNcYb"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_dc,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLiRzl1hNcYb"
      },
      "outputs": [],
      "source": [
        "probs = model_dc.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OozVhvQOFNi"
      },
      "source": [
        "**Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "  temp_acc = []\n",
        "\n",
        "  max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
        "\n",
        "  min_samples_split = trial.suggest_int(\"min_samples_split\",2,50)\n",
        "\n",
        "  min_samples_leaf = trial.suggest_int(\"min_samples_leaf\",1,50)\n",
        "\n",
        "  max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\",5,100)\n",
        "\n",
        "  n_estimators = trial.suggest_int(\"n_estimators\",10,100)\n",
        "\n",
        "  #K-fold stratified Split\n",
        "  for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
        "    y_train_temp = y_train[train_index]\n",
        "    x_train_temp = x_train[train_index]\n",
        "\n",
        "    y_val_temp = y_train[test_index]\n",
        "    x_val_temp = x_train[test_index]\n",
        "\n",
        "    model = RandomForestClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, max_leaf_nodes = max_leaf_nodes,n_estimators=n_estimators,random_state=42)\n",
        "\n",
        "    #Training the Model\n",
        "    model.fit(x_train_temp,y_train_temp.ravel())\n",
        "\n",
        "    y_pred = model.predict(x_val_temp)\n",
        "\n",
        "    v0 = metrics.accuracy_score(y_val_temp, y_pred)\n",
        "\n",
        "    temp_acc.append(v0)\n",
        "\n",
        "  return np.array(temp_acc).mean()\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(study.best_params)\n"
      ],
      "metadata": {
        "id": "C3JZNOiUBG4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = study.best_params"
      ],
      "metadata": {
        "id": "U6GpDpWtBG4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = temp_dict[\"max_depth\"]\n",
        "\n",
        "min_samples_split = temp_dict[\"min_samples_split\"]\n",
        "\n",
        "min_samples_leaf = temp_dict[\"min_samples_leaf\"]\n",
        "\n",
        "max_leaf_nodes = temp_dict[\"max_leaf_nodes\"]\n",
        "\n",
        "n_estimators = temp_dict[\"n_estimators\"]"
      ],
      "metadata": {
        "id": "QXFFcvNRBG4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqoC8_iOOaEm"
      },
      "outputs": [],
      "source": [
        "model_rfc = RandomForestClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, max_leaf_nodes = max_leaf_nodes,n_estimators=n_estimators,random_state=42).fit(x_train,y_train)\n",
        "y_pred_rfc=model_rfc.predict(x_test)\n",
        "\n",
        "\n",
        "print(\"Training Accuracy is:-\",model_rfc.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_rfc.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi_Hw-BUOaEn"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_rfc, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vga9ryulOaEn"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_rfc,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWr7uNcsOaEn"
      },
      "outputs": [],
      "source": [
        "probs = model_rfc.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3unIt6YPDMj"
      },
      "source": [
        "**XGBoost Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPd0Tpyqeros"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "\n",
        "  temp_acc = []\n",
        "\n",
        "  max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
        "\n",
        "  #K-fold stratified Split\n",
        "  for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
        "    y_train_temp = y_train[train_index]\n",
        "    x_train_temp = x_train[train_index]\n",
        "\n",
        "    y_val_temp = y_train[test_index]\n",
        "    x_val_temp = x_train[test_index]\n",
        "\n",
        "    model = XGBClassifier(max_depth=max_depth,random_state=42)\n",
        "\n",
        "    #Training the Model\n",
        "    model.fit(x_train_temp,y_train_temp.ravel())\n",
        "\n",
        "    y_pred = model.predict(x_val_temp)\n",
        "\n",
        "    v0 = metrics.accuracy_score(y_val_temp, y_pred)\n",
        "    temp_acc.append(v0)\n",
        "\n",
        "  return np.array(temp_acc).mean()\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(study.best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = study.best_params"
      ],
      "metadata": {
        "id": "gN4LMjds1zEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = temp_dict[\"max_depth\"]"
      ],
      "metadata": {
        "id": "1bVn6zpU1zEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-hGCwVePJJt"
      },
      "outputs": [],
      "source": [
        "model_xgb = XGBClassifier(max_depth=max_depth,random_state=42).fit(x_train,y_train)\n",
        "y_pred_xgb=model_xgb.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy is:-\",model_xgb.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_xgb.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnRXtgBOPJJu"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_xgb, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APAcsB0TPJJu"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_xgb,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwBSGp5uPJJv"
      },
      "outputs": [],
      "source": [
        "probs = model_xgb.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxCbzF5qEs3j"
      },
      "source": [
        "**Gaussian Process Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1Wuq8N2P1a3"
      },
      "outputs": [],
      "source": [
        "lbound = 1e-5\n",
        "rbound = 1e5\n",
        "\n",
        "n_restarts = 50\n",
        "\n",
        "n_features = len(x_train[0])\n",
        "\n",
        "# kernel=C(1.0, (lbound,rbound)) * RBF(n_features*[n_features], (lbound,rbound))  + WhiteKernel()\n",
        "\n",
        "model_gpc = GaussianProcessClassifier().fit(x_train,y_train)\n",
        "y_pred_gpc=model_gpc.predict(x_test)\n",
        "\n",
        "print(\"Classification Accuracy is:-\",model_gpc.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbkTEIOcP1a3"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_gpc, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EGnmaBKP1a3"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_gpc,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRWv5gLNP1a4"
      },
      "outputs": [],
      "source": [
        "probs = model_gpc.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NE4w-JPSX9n"
      },
      "source": [
        "**KNN Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah3Y46fbfth3"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "\n",
        "  temp_acc = []\n",
        "\n",
        "  n_neighbors = trial.suggest_int(\"n_neighbors\", 1, 10)\n",
        "  weights = trial.suggest_categorical(\"weights\",[\"uniform\", \"distance\"])\n",
        "  p = trial.suggest_int(\"p\", 1, 5)\n",
        "\n",
        "  #K-fold stratified Split\n",
        "  for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
        "    y_train_temp = y_train[train_index]\n",
        "    x_train_temp = x_train[train_index]\n",
        "\n",
        "    y_val_temp = y_train[test_index]\n",
        "    x_val_temp = x_train[test_index]\n",
        "\n",
        "    model = KNeighborsClassifier(n_neighbors=n_neighbors,weights=weights,p=p)\n",
        "\n",
        "    #Training the Model\n",
        "    model.fit(x_train_temp,y_train_temp.ravel())\n",
        "\n",
        "    y_pred = model.predict(x_val_temp)\n",
        "\n",
        "    v0 = metrics.accuracy_score(y_val_temp, y_pred)\n",
        "\n",
        "    if (len(temp_data_np)==0):\n",
        "      v0 = 0\n",
        "\n",
        "    temp_acc.append(v0)\n",
        "\n",
        "  return np.array(temp_acc).mean()\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "print(study.best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = study.best_params"
      ],
      "metadata": {
        "id": "_Kr49IcQFmpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_neighbors = temp_dict[\"n_neighbors\"]\n",
        "weights = temp_dict[\"weights\"]\n",
        "p = temp_dict[\"p\"]"
      ],
      "metadata": {
        "id": "vRtZS952FmpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4drDfmbLSdYM"
      },
      "outputs": [],
      "source": [
        "model_knn = KNeighborsClassifier(n_neighbors=n_neighbors,weights=weights,p=p).fit(x_train,y_train)\n",
        "y_pred_knn=model_knn.predict(x_test)\n",
        "\n",
        "print(\"Classification Accuracy is:-\",model_knn.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORN007CKSdYM"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_knn, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACF99FKrSdYM"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_knn,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiqRLrwdSdYM"
      },
      "outputs": [],
      "source": [
        "probs = model_knn.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-tRgLFRh41W"
      },
      "source": [
        "**LDA Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PNJfjqjh9Kc"
      },
      "outputs": [],
      "source": [
        "model_lda =LinearDiscriminantAnalysis().fit(x_train,y_train)\n",
        "y_pred_lda=model_lda.predict(x_test)\n",
        "\n",
        "print(\"Classification Accuracy is:-\",model_lda.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZV9XddEh9Kd"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_lda, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXALN-tCh9Kd"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_lda,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qc7UIh5h9Kd"
      },
      "outputs": [],
      "source": [
        "probs = model_lda.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPvTkEeCytig"
      },
      "source": [
        "**Support Vector Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "  temp_acc = []\n",
        "\n",
        "  C = trial.suggest_float(\"C\", 0, 1)\n",
        "\n",
        "  kernel = trial.suggest_categorical(\"kernel\",[\"linear\", \"poly\", \"rbf\", \"sigmoid\"])\n",
        "\n",
        "  #K-fold stratified Split\n",
        "  for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
        "    y_train_temp = y_train[train_index]\n",
        "    x_train_temp = x_train[train_index]\n",
        "\n",
        "    y_val_temp = y_train[test_index]\n",
        "    x_val_temp = x_train[test_index]\n",
        "\n",
        "    model = SVC(probability=True, C=C, kernel=kernel,random_state = 42)\n",
        "\n",
        "    #Training the Model\n",
        "    model.fit(x_train_temp,y_train_temp.ravel())\n",
        "\n",
        "    y_pred = model.predict(x_val_temp)\n",
        "\n",
        "    v0 = metrics.accuracy_score(y_val_temp, y_pred)\n",
        "\n",
        "    if (len(temp_data_np)==0):\n",
        "      v0 = 0\n",
        "\n",
        "    temp_acc.append(v0)\n",
        "\n",
        "  return np.array(temp_acc).mean()\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "print(study.best_params)\n"
      ],
      "metadata": {
        "id": "NQqnGraY3PT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = study.best_params"
      ],
      "metadata": {
        "id": "vMuJb4734fSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C = temp_dict[\"C\"]\n",
        "\n",
        "kernel = temp_dict[\"kernel\"]"
      ],
      "metadata": {
        "id": "0ceNydAP4-da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-wPTZc2y2ur"
      },
      "outputs": [],
      "source": [
        "model_svc = SVC(probability=True, C=C, kernel=kernel,random_state = 42).fit(x_train,y_train)\n",
        "y_pred_svc=model_svc.predict(x_test)\n",
        "\n",
        "print(\"Classification Accuracy is:-\",model_svc.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCL28v9zy2ur"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_svc, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLvR1dCFy2ur"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_svc,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKjc8lXSy2ur"
      },
      "outputs": [],
      "source": [
        "probs = model_svc.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HignqKFVwgP2"
      },
      "source": [
        "**Sk-learn Neural Network Optimisation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRr3XA0nwkAv"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "\n",
        "  temp_acc = []\n",
        "\n",
        "  n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
        "\n",
        "  layers = []\n",
        "\n",
        "  for i in range(n_layers):\n",
        "    hidden_neuron = trial.suggest_int(\"Num Hidden_\"+str(i), 1, 500)\n",
        "    layers.append(hidden_neuron)\n",
        "\n",
        "  #L2 Regularisation term\n",
        "  alpha = trial.suggest_float(\"alpha\",1e-5,1e-2)\n",
        "\n",
        "  learning_rate = trial.suggest_categorical(\"learning_rate\",[\"constant\", \"invscaling\", \"adaptive\"])\n",
        "\n",
        "  learning_rate_init = trial.suggest_float(\"learning_rate_init\",1e-5,1e-1)\n",
        "\n",
        "  max_iter = trial.suggest_int(\"max_iter\", 50, 2000)\n",
        "\n",
        "  tol = trial.suggest_float(\"tol\",1e-5,1e-3)\n",
        "\n",
        "  #K-fold stratified Split\n",
        "  for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
        "    y_train_temp = y_train[train_index]\n",
        "    x_train_temp = x_train[train_index]\n",
        "\n",
        "    #Data for C-means\n",
        "    x_train_data_temp = x_train_temp[:,0:len(x_train_temp[0])-4]\n",
        "    x_train_meta_temp = x_train_temp[:,len(x_train_temp[0])-4:]\n",
        "\n",
        "    y_val_temp = y_train[test_index]\n",
        "    x_val_temp = x_train[test_index]\n",
        "\n",
        "\n",
        "    model = MLPClassifier(hidden_layer_sizes=layers , alpha = alpha, learning_rate= learning_rate, learning_rate_init= learning_rate_init, max_iter= max_iter,tol=tol,early_stopping=True,validation_fraction=0.3 ,random_state=42)\n",
        "\n",
        "    #Training the Model\n",
        "\n",
        "    model.fit(x_train_temp,y_train_temp.ravel())\n",
        "\n",
        "    y_pred = model.predict(x_val_temp)\n",
        "\n",
        "    v0 = metrics.accuracy_score(y_val_temp, y_pred)\n",
        "\n",
        "    if (len(temp_data_np)==0):\n",
        "      v0 = 0\n",
        "\n",
        "    temp_acc.append(v0)\n",
        "\n",
        "  return np.array(temp_acc).mean()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "print(study.best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dict = study.best_params"
      ],
      "metadata": {
        "id": "nyHfswkE5Slw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = temp_dict[\"n_layers\"]\n",
        "\n",
        "layers = []\n",
        "\n",
        "for i in range(n_layers):\n",
        "  hidden_neuron = temp_dict[\"Num Hidden_\"+str(i)]\n",
        "  layers.append(hidden_neuron)\n",
        "\n",
        "\n",
        "#L2 Regularisation term\n",
        "alpha = temp_dict[\"alpha\"]\n",
        "\n",
        "learning_rate = temp_dict[\"learning_rate\"]\n",
        "\n",
        "learning_rate_init = temp_dict[\"learning_rate_init\"]\n",
        "\n",
        "max_iter = temp_dict[\"max_iter\"]\n",
        "\n",
        "tol = temp_dict[\"tol\"]\n",
        "\n",
        "model_nn = MLPClassifier(hidden_layer_sizes=layers , alpha = alpha, learning_rate= learning_rate, learning_rate_init= learning_rate_init, max_iter= max_iter,tol=tol,early_stopping=True,validation_fraction=0.3 ,random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "#Training the Model\n",
        "model_nn.fit(x_train,y_train.ravel())\n"
      ],
      "metadata": {
        "id": "3C2OKnqN5TR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3EpaiBi_BJP"
      },
      "outputs": [],
      "source": [
        "y_pred_nn=model_nn.predict(x_test)\n",
        "\n",
        "print(\"Accuracy on the training data is:-\",model_nn.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_nn.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2w-UXI_m_BJQ"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_nn, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLN124yY_BJQ"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_nn,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_Xs9gS0VPSa"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_pred_nn)):\n",
        "  if (y_pred_nn[i]==0 and y_pred_nn[i]!=y_test[i]):\n",
        "    print(sample_id_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vef0iswcVPSa"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_pred_nn)):\n",
        "  if (y_pred_nn[i]==1 and y_pred_nn[i]!=y_test[i]):\n",
        "    print(sample_id_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dlj8vh0Q_BJQ"
      },
      "outputs": [],
      "source": [
        "probs = model_nn.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    }
  ]
}