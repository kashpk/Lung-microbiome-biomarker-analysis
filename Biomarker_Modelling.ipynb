{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FbO7KKps1Wx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "import copy\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "\n",
        "#Pre-Processing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "#models\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import tree\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "!pip install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#Kernels\n",
        "from sklearn.gaussian_process.kernels import RBF, WhiteKernel,Matern,ExpSineSquared,RationalQuadratic, ConstantKernel as C\n",
        "\n",
        "#Scipy\n",
        "from scipy.spatial import distance\n",
        "import scipy\n",
        "import scipy.optimize as opt\n",
        "from scipy.optimize import differential_evolution\n",
        "from scipy.optimize import basinhopping\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import norm\n",
        "\n",
        "#Pytorch\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "#For plots\n",
        "!pip install kaleido\n",
        "!sudo apt-get install poppler-utils\n",
        "\n",
        "#Optuna\n",
        "!pip install optuna\n",
        "import optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LdDMK7zt3ew"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ihdavjar/LCBM_analysis.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYi1lJ590xl"
      },
      "source": [
        "**Data Preparation for the Lefse**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKNYCF0T94RQ"
      },
      "outputs": [],
      "source": [
        "data_1=pd.read_csv(\"/content/LCBM_analysis/feature-table.tsv\")\n",
        "data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0jC1tMMuNT4"
      },
      "outputs": [],
      "source": [
        "org_data=pd.read_csv(\"/content/LCBM_analysis/feature-table.tsv\")\n",
        "\n",
        "taxonomy_arr=list(org_data[\"taxonomy\"])\n",
        "otu_ids=list(org_data[\"otu_id\"])\n",
        "print(taxonomy_arr)\n",
        "print(otu_ids)\n",
        "\n",
        "#Removing the taxonomy and the otu_ids from the feature table\n",
        "org_data=org_data.drop([\"otu_id\",\"taxonomy\"],axis=1)\n",
        "\n",
        "\n",
        "temp_data=np.array(org_data)\n",
        "temp_otus=[]\n",
        "for i in range(len(temp_data)):\n",
        "  temp_otus.append(\"Otu\"+str(i+1))\n",
        "\n",
        "\n",
        "#Adding the labels to feature table\n",
        "org_data=org_data.T\n",
        "org_data.columns=temp_otus\n",
        "\n",
        "print(org_data)\n",
        "temp_data=pd.read_csv(\"/content/LCBM_analysis/label_data.csv\")\n",
        "temp_data=temp_data.drop(['Unnamed: 0'],axis=1)\n",
        "temp_data_np=np.array(temp_data)\n",
        "\n",
        "print(temp_data)\n",
        "\n",
        "dict_temp={}\n",
        "for i in range(len(temp_data_np)):\n",
        "  if (temp_data_np[i,1]==\"Squamous cell carcinoma\"):\n",
        "    dict_temp[temp_data_np[i,0]]=\"Squamous\"\n",
        "  else:\n",
        "    dict_temp[temp_data_np[i,0]]=temp_data_np[i,1]\n",
        "\n",
        "l_temp_row=list(org_data.index)\n",
        "temp_labels=[]\n",
        "\n",
        "for i in range(len(l_temp_row)):\n",
        "  if (dict_temp[l_temp_row[i]]==\"Adenosquamous carcinoma\"):\n",
        "    org_data.drop([l_temp_row[i]],axis=0,inplace=True)\n",
        "  else:\n",
        "    temp_labels.append(dict_temp[l_temp_row[i]])\n",
        "\n",
        "\n",
        "org_data_np=np.array(org_data)\n",
        "org_data\n",
        "\n",
        "# org_data.insert(loc=0,column=\"label\",value=0.03)\n",
        "# org_data.insert(loc=1,column=\"Group\",value=list(org_data.index))\n",
        "# org_data.insert(loc=2,column=\"numOtus\",value=3607)\n",
        "org_data['treatment']=temp_labels\n",
        "\n",
        "\n",
        "org_data.to_csv('complete_otus.csv',index=False)\n",
        "# files.download('complete_otus.csv')\n",
        "org_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsnDzdaIum70"
      },
      "source": [
        "**Data Standardisation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGldQP__upS3"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "org_data_np=np.array(org_data)\n",
        "\n",
        "labels=le.fit_transform(org_data_np[:,len(org_data_np[0])-1])\n",
        "\n",
        "org_data_np[:,len(org_data_np[0])-1]=labels\n",
        "\n",
        "stan_data=pd.DataFrame(org_data_np,columns=org_data.columns,index=org_data.index)\n",
        "stan_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfBZxGbCvGn7"
      },
      "outputs": [],
      "source": [
        "l_cols=taxonomy_arr\n",
        "print(l_cols)\n",
        "print(len(l_cols))\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  print(temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaOCVgqou7Sd"
      },
      "source": [
        "**Phylum Wise Division**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzG3tcirvJCh"
      },
      "outputs": [],
      "source": [
        "phyllum_labels=[]\n",
        "count_no_phyllum=0\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)!=1):\n",
        "    if (temp[1] not in phyllum_labels):\n",
        "      phyllum_labels.append(temp[1])\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)==1):\n",
        "    count_no_phyllum=count_no_phyllum+1\n",
        "\n",
        "print(\"Number of Taxa without the phyllum labels:-\",count_no_phyllum)\n",
        "\n",
        "print(\"No. of distinct phyllum are:-\",len(phyllum_labels))\n",
        "print(phyllum_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOW1fk33vMxd"
      },
      "outputs": [],
      "source": [
        "temp_dict={}\n",
        "for i in range(len(phyllum_labels)):\n",
        "  temp_dict[phyllum_labels[i]]=0\n",
        "\n",
        "temp_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfzeqbsSvOib"
      },
      "outputs": [],
      "source": [
        "numpy_data=np.array(stan_data)\n",
        "print(l_cols)\n",
        "stan_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBo5sKWevYmM"
      },
      "outputs": [],
      "source": [
        "temps_arr=[]\n",
        "\n",
        "for i in range(len(numpy_data)):\n",
        "  temp_arr=numpy_data[i,0:len(numpy_data[0])-1].ravel()\n",
        "  new_dict=copy.deepcopy(temp_dict)\n",
        "  for j in range(len(temp_arr)):\n",
        "    temp=l_cols[j]\n",
        "    temp=temp.split(\";\")\n",
        "    if (len(temp)!=1):\n",
        "      new_dict[temp[1]]=new_dict[temp[1]]+temp_arr[j]\n",
        "  temps_arr.append(list(new_dict.values()))\n",
        "\n",
        "temps_arr=np.array(temps_arr)\n",
        "\n",
        "temp_columns=list(temp_dict.keys())\n",
        "\n",
        "phylum_data=pd.DataFrame(temps_arr,columns=np.array(temp_columns),index=np.array(stan_data.index))\n",
        "phylum_data['treatment']=list(stan_data[\"treatment\"])\n",
        "print(temps_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4Daec5rvcFG"
      },
      "outputs": [],
      "source": [
        "phylum_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9S4m6Ht0BdS"
      },
      "source": [
        "**Lefse Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITTOrq-MSPdx"
      },
      "outputs": [],
      "source": [
        "data_1=pd.read_csv(\"/content/LCBM_analysis/phylum_data.csv\")\n",
        "data_1.dropna(inplace=True)\n",
        "data_1.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
        "data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj3fO3B_Dq4s"
      },
      "outputs": [],
      "source": [
        "data_np=np.array(data_1)\n",
        "temp_labels=[]\n",
        "for i in range(len(data_1)):\n",
        "  if (data_np[i,1]<0):\n",
        "    temp_labels.append(\"Adenocarcinoma\")\n",
        "  else:\n",
        "    temp_labels.append(\"Squamous\")\n",
        "\n",
        "data_1[\"Class\"]=temp_labels\n",
        "\n",
        "temp_data.append(data_1)\n",
        "data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "segjlUCPFb0p"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "# data_canada = px.data.gapminder().query(\"country == 'Canada'\")\n",
        "fig = px.bar(data_1, x='scores', y='Names',orientation='h',color=\"Class\",labels=dict(Names=\"\", scores=\"LDA Score\", Class=\"Groups\"))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlxPbdi_0Dpx"
      },
      "outputs": [],
      "source": [
        "data_1=pd.read_csv(\"/content/LCBM_analysis/phylum_data.csv\",sep=\",\")\n",
        "data_1.dropna(inplace=True)\n",
        "data_1.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
        "\n",
        "data_1 = data_1[abs(data_1['scores'])>1]\n",
        "data_1_np=np.array(data_1)\n",
        "data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYo0j7D_0FSS"
      },
      "outputs": [],
      "source": [
        "chosen_phylum=data_1_np[:,0]\n",
        "\n",
        "\n",
        "l = chosen_phylum\n",
        "final_list = []\n",
        "for i in l:\n",
        "  final_list.append(i.strip())\n",
        "\n",
        "chosen_phylum=final_list\n",
        "print(\"Statistically significant phylum are:\\n\",chosen_phylum)\n",
        "\n",
        "temp_phylums_names=[]\n",
        "for i in range(len(chosen_phylum)):\n",
        "  temp_phylums_names.append(\" \"+str(chosen_phylum[i]))\n",
        "\n",
        "chosen_columns1=phylum_data.loc[:,temp_phylums_names]\n",
        "\n",
        "chosen_columns1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVQ2N3mg5xDF"
      },
      "source": [
        "**Genus Wise Division**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TscRElP6ESe"
      },
      "outputs": [],
      "source": [
        "genus_labels=[]\n",
        "l_cols=taxonomy_arr\n",
        "\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)>5):\n",
        "    if (temp[5] not in genus_labels):\n",
        "      genus_labels.append(temp[5])\n",
        "\n",
        "count_no_phyllum=0\n",
        "for i in range(len(l_cols)):\n",
        "  temp=l_cols[i]\n",
        "  temp=temp.split(\";\")\n",
        "  if (len(temp)==5):\n",
        "    count_no_phyllum=count_no_phyllum+1\n",
        "\n",
        "print(\"Number of Taxa without the Genus labels:-\",count_no_phyllum)\n",
        "\n",
        "print(\"No. of distinct Genus:-\",len(genus_labels))\n",
        "print(genus_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRDhIJKn6Lt6"
      },
      "outputs": [],
      "source": [
        "temp_dict={}\n",
        "for i in range(len(genus_labels)):\n",
        "  temp_dict[genus_labels[i]]=0\n",
        "\n",
        "temp_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4zoXp-f6O1T"
      },
      "outputs": [],
      "source": [
        "numpy_data=np.array(stan_data)\n",
        "print(l_cols)\n",
        "stan_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-lhlNLn6VYX"
      },
      "outputs": [],
      "source": [
        "temps_arr=[]\n",
        "for i in range(len(numpy_data)):\n",
        "\n",
        "  temp_arr=numpy_data[i,0:len(numpy_data[0])-1].ravel()\n",
        "  new_dict=copy.deepcopy(temp_dict)\n",
        "  for j in range(len(temp_arr)):\n",
        "    temp=l_cols[j]\n",
        "    temp=temp.split(\";\")\n",
        "    if (len(temp)>5):\n",
        "      new_dict[temp[5]]=new_dict[temp[5]]+temp_arr[j]\n",
        "  temps_arr.append(list(new_dict.values()))\n",
        "\n",
        "temps_arr=np.array(temps_arr)\n",
        "genus_data=pd.DataFrame(temps_arr,columns=list(temp_dict.keys()),index=org_data.index)\n",
        "genus_data['treatment']=list(stan_data[\"treatment\"])\n",
        "print(temps_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtdIt6U-6dbm"
      },
      "outputs": [],
      "source": [
        "genus_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqJLAWy26tlY"
      },
      "source": [
        "**lefse data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rbp2AvoLGazR"
      },
      "outputs": [],
      "source": [
        "data_1=pd.read_csv(\"/content/LCBM_analysis/genus_data.csv\")\n",
        "data_1.dropna(inplace=True)\n",
        "data_1.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
        "data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeIZSdVVGazR"
      },
      "outputs": [],
      "source": [
        "data_np=np.array(data_1)\n",
        "temp_labels=[]\n",
        "for i in range(len(data_1)):\n",
        "  if (data_np[i,1]<0):\n",
        "    temp_labels.append(\"Adenocarcinoma\")\n",
        "  else:\n",
        "    temp_labels.append(\"Squamous\")\n",
        "\n",
        "data_1[\"Class\"]=temp_labels\n",
        "\n",
        "temp_data.append(data_1)\n",
        "\n",
        "data_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVCmfWWBGazS"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "# data_canada = px.data.gapminder().query(\"country == 'Canada'\")\n",
        "fig = px.bar(data_1, x='scores', y='Names',orientation='h',color=\"Class\",labels=dict(Names=\"\", scores=\"LDA Score\", Class=\"Groups\"))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEaCHj3T2KJE"
      },
      "outputs": [],
      "source": [
        "data_2=pd.read_csv(\"/content/LCBM_analysis/genus_data.csv\",sep=\",\")\n",
        "data_2.dropna(inplace=True)\n",
        "data_2.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
        "\n",
        "data_2 = data_2[abs(data_2['scores'])>1]\n",
        "data_2_np=np.array(data_2)\n",
        "data_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h6vl3iB56c-"
      },
      "outputs": [],
      "source": [
        "chosen_genus=data_2_np[:,0]\n",
        "\n",
        "\n",
        "l = chosen_genus\n",
        "final_list = []\n",
        "for i in l:\n",
        "  final_list.append(i.strip())\n",
        "\n",
        "chosen_genus=final_list\n",
        "print(\"Statistically significant genus are:\\n\",chosen_genus)\n",
        "\n",
        "temp_genus_names=[]\n",
        "for i in range(len(chosen_genus)):\n",
        "  if (str(chosen_genus[i])=='g__0319.6G20'):\n",
        "    temp_genus_names.append(\" g__0319-6G20\")\n",
        "  else:\n",
        "    temp_genus_names.append(\" \"+str(chosen_genus[i]))\n",
        "\n",
        "chosen_columns2=genus_data.loc[:,temp_genus_names]\n",
        "\n",
        "chosen_columns2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNbmVyvJD9DX"
      },
      "source": [
        "**Collecting Useful Columns from the MetaData**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l3Ct94iEB0Z"
      },
      "outputs": [],
      "source": [
        "meta_data=pd.read_csv(\"/content/LCBM_analysis/SraRunTable.tsv\",sep='\\t')\n",
        "meta_data.drop([0],axis=0,inplace=True)\n",
        "meta_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMYzcm3BE2qE"
      },
      "source": [
        "**Choosing the important columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQuHCQP6E2ZF"
      },
      "outputs": [],
      "source": [
        "print(meta_data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeEC_jjbFQhL"
      },
      "source": [
        "**Choosing env_material, Host_Age, host_sex, smoker**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUOFgjhRGJbk"
      },
      "outputs": [],
      "source": [
        "meta_data=meta_data[[\" Sample-id\",\"env_material\",\"host_sex\",\"Host_Age\",\"smoker\"]]\n",
        "meta_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iktdv-kpIV6m"
      },
      "outputs": [],
      "source": [
        "meta_data_np=np.array(meta_data)\n",
        "print(meta_data_np)\n",
        "\n",
        "temp_sample_dict={}\n",
        "\n",
        "for i in range(len(meta_data_np)):\n",
        "  temp_sample_dict[meta_data_np[i,0]]=meta_data_np[i,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fey4uYuJYR7"
      },
      "outputs": [],
      "source": [
        "temp_sample_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByR_FtinJgjx"
      },
      "outputs": [],
      "source": [
        "temp_sample_names=list(phylum_data.index)\n",
        "\n",
        "chosen_column3_np=[]\n",
        "\n",
        "for i in range(len(temp_sample_names)):\n",
        "  chosen_column3_np.append(temp_sample_dict[temp_sample_names[i]])\n",
        "\n",
        "chosen_column3_np=np.array(chosen_column3_np)\n",
        "chosen_column3_np\n",
        "\n",
        "chosen_columns3=pd.DataFrame(chosen_column3_np,index=temp_sample_names,columns=list(meta_data.columns)[1:])\n",
        "chosen_columns3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCbpk0UhEo4C"
      },
      "source": [
        "**Removing Instances with missing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh6Pr-kVEtcz"
      },
      "outputs": [],
      "source": [
        "meta_data.dropna(inplace=True)\n",
        "meta_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB06Qg7C7S_R"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En43oru57Vg0"
      },
      "outputs": [],
      "source": [
        "chosen_column1_np=np.array(chosen_columns1)\n",
        "chosen_column2_np=np.array(chosen_columns2)\n",
        "chosen_column3_np=np.array(chosen_columns3)\n",
        "\n",
        "data=np.array(stan_data)\n",
        "\n",
        "x_data=np.c_[chosen_column1_np,chosen_column2_np,chosen_column3_np]\n",
        "print(np.shape(x_data))\n",
        "\n",
        "y_data=np.array(stan_data[\"treatment\"]).astype(int)\n",
        "\n",
        "result_data=pd.DataFrame(x_data,index=phylum_data.index,columns=list(chosen_columns1.columns)+list(chosen_columns2.columns)+list(chosen_columns3.columns))\n",
        "result_data[\"label\"]=y_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3R8dAdtzLScO"
      },
      "outputs": [],
      "source": [
        "# result_data.to_csv(\"data_dnn.csv\")\n",
        "# files.download(\"data_dnn.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7euUC3WMMb0W"
      },
      "source": [
        "**label encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5hz5QNQMeOL"
      },
      "outputs": [],
      "source": [
        "le1 = preprocessing.LabelEncoder()\n",
        "le2 = preprocessing.LabelEncoder()\n",
        "le3 = preprocessing.LabelEncoder()\n",
        "\n",
        "result_data[\"env_material\"]=le1.fit_transform(result_data[\"env_material\"])\n",
        "result_data[\"host_sex\"]=le2.fit_transform(result_data[\"host_sex\"])\n",
        "result_data[\"smoker\"]=le3.fit_transform(result_data[\"smoker\"])\n",
        "\n",
        "# result_data.drop(['env_material','Host_Age','host_sex'],axis=1,inplace=True)\n",
        "result_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_data"
      ],
      "metadata": {
        "id": "8qgH0RKrx5p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bray_curtis_array(l1,l2):\n",
        "  bc=distance.braycurtis(l1.astype(float),l2.astype(float))\n",
        "  return bc\n",
        "\n",
        "\n",
        "def bray_curtis_comp(data):\n",
        "  d_mat=[]\n",
        "\n",
        "  for i in range(len(data)):\n",
        "    d_mat1=[]\n",
        "    for j in range(len(data)):\n",
        "      temp_1=data[i,:len(data[0])-1]\n",
        "      temp_2=data[j,:len(data[0])-1]\n",
        "      d_mat1.append(bray_curtis_array(temp_1,temp_2))\n",
        "    d_mat.append(d_mat1)\n",
        "  d_mat=np.array(d_mat)\n",
        "  return d_mat\n",
        "\n",
        "result_data_out_np=np.array(result_data)\n",
        "bray_curtis_data=pd.DataFrame(bray_curtis_comp(result_data_out_np))\n"
      ],
      "metadata": {
        "id": "oWtRRAudzLz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bray_curtis_data_np=np.array(bray_curtis_data)\n",
        "\n",
        "X = bray_curtis_data_np\n",
        "pca = PCA(n_components=4)\n",
        "pca.fit(X)\n",
        "\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "x_new=pca.transform(X)\n",
        "\n",
        "x=x_new[:,0]\n",
        "y=x_new[:,1]\n",
        "z=x_new[:,2]\n",
        "z1=x_new[:,3]"
      ],
      "metadata": {
        "id": "ZlePJanBzWLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(x=x, y=y,color=org_data['treatment'])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "KMq8bSlNzans"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from plotly.offline import plot, iplot, init_notebook_mode\n",
        "from plotly.subplots import make_subplots\n",
        "# df = px.data.iris()\n",
        "fig = px.scatter_3d(x=x, y=y, z=z,\n",
        "              color=org_data['treatment'])\n",
        "\n",
        "\n",
        "\n",
        "# pio.write_image(fig, 'image.png',scale=7, width=1080, height=1080)\n",
        "# files.download('image.png')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "WRQuNilQzYhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F0TIBJP7QWw"
      },
      "source": [
        "**Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5OhFVU5dNWP"
      },
      "outputs": [],
      "source": [
        "result_data_no_out = copy.deepcopy(result_data)\n",
        "x_data_pd=result_data_no_out.drop(['label'],axis=1)\n",
        "\n",
        "#Normalisation\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "x_data_pd_stan=pd.DataFrame(scaler.fit_transform(x_data_pd),columns=x_data_pd.columns,index=x_data_pd.index)\n",
        "\n",
        "x_data_pd_stan= x_data_pd\n",
        "\n",
        "x_data_pd_stan[\"sample_id\"] = result_data.index\n",
        "\n",
        "x_data_pd['label']=result_data['label']\n",
        "\n",
        "x_data_pd_stan['label']=result_data['label']\n",
        "\n",
        "\n",
        "result_data=x_data_pd_stan\n",
        "\n",
        "\n",
        "result_data_class0=result_data[result_data[\"label\"]==0]\n",
        "result_data_class1=result_data[result_data[\"label\"]==1]\n",
        "\n",
        "result_data_class_0_np=np.array(result_data_class0)\n",
        "result_data_class_1_np=np.array(result_data_class1)\n",
        "\n",
        "print(np.unique(result_data_class_0_np[:,len(result_data_class_0_np[0])-1]))\n",
        "print(np.unique(result_data_class_1_np[:,len(result_data_class_1_np[0])-1]))\n",
        "\n",
        "x_class_0=result_data_class_0_np[:,0:len(result_data_class_0_np[0])-1]\n",
        "y_class_0=result_data_class_0_np[:,len(result_data_class_0_np[0])-1].astype(int)\n",
        "\n",
        "x_class_1=result_data_class_1_np[:,0:len(result_data_class_1_np[0])-1]\n",
        "y_class_1=result_data_class_1_np[:,len(result_data_class_1_np[0])-1].astype(int)\n",
        "\n",
        "#CLASS 0\n",
        "x_train_0, x_temp_0, y_train_0, y_temp_0 = train_test_split(x_class_0, y_class_0, test_size=0.3,shuffle=True, random_state=42)\n",
        "x_val_0, x_test_0, y_val_0, y_test_0 = train_test_split(x_temp_0, y_temp_0, test_size=0.5,shuffle=True, random_state=42)\n",
        "\n",
        "#CLASS 1\n",
        "x_train_1, x_temp_1, y_train_1, y_temp_1 = train_test_split(x_class_1, y_class_1, test_size=0.3,shuffle=True, random_state=42)\n",
        "x_val_1, x_test_1, y_val_1, y_test_1 = train_test_split(x_temp_1, y_temp_1, test_size=0.5,shuffle=True, random_state=42)\n",
        "\n",
        "#Train Data\n",
        "x_train=np.r_[x_train_0,x_train_1]\n",
        "y_train=np.r_[y_train_0,y_train_1]\n",
        "\n",
        "sample_id_train = x_train[:,len(x_train[0])-1]\n",
        "\n",
        "x_train = x_train[:,:len(x_train[0])-1].astype(float)\n",
        "\n",
        "\n",
        "#Val Data\n",
        "x_val=np.r_[x_val_0,x_val_1]\n",
        "y_val=np.r_[y_val_0,y_val_1]\n",
        "\n",
        "sample_id_val = x_val[:,len(x_val[0])-1]\n",
        "\n",
        "x_val = x_val[:,:len(x_val[0])-1].astype(float)\n",
        "\n",
        "#Test Data\n",
        "x_test=np.r_[x_test_0,x_test_1]\n",
        "y_test=np.r_[y_test_0,y_test_1]\n",
        "\n",
        "sample_id_test = x_test[:,len(x_test[0])-1]\n",
        "\n",
        "x_test = x_test[:,:len(x_test[0])-1].astype(float)\n",
        "\n",
        "\n",
        "print(\"Number of Instances in Training Data of class 0:-\",len(x_train_0))\n",
        "print(\"Number of Instances in Training Data of class 1:-\",len(x_train_1))\n",
        "\n",
        "print(\"Number of Instances in Validation Data of class 0:-\",len(x_val_0))\n",
        "print(\"Number of Instances in Validation Data of class 1:-\",len(x_val_1))\n",
        "\n",
        "print(\"Number of Instances in Testing Data of class 0:-\",len(x_test_0))\n",
        "print(\"Number of Instances in Testing Data of class 1:-\",len(x_test_1))\n",
        "\n",
        "\n",
        "\n",
        "#Test Full Data\n",
        "x_test_1=np.r_[x_temp_0,x_temp_1]\n",
        "y_test_1=np.r_[y_temp_0,y_temp_1]\n",
        "\n",
        "sample_id_test_1 = x_test_1[:,len(x_test_1[0])-1]\n",
        "\n",
        "x_test_1 = x_test_1[:,:len(x_test_1[0])-1].astype(float)\n",
        "\n",
        "print(\"Number of Instance in Testing Data 1 of class 0:-\",len(x_temp_0))\n",
        "print(\"Number of Instance in Testing Data 1 of class 1:-\",len(x_temp_1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOJT7OwGt1vh"
      },
      "source": [
        "**Downloading The Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvywkKx8t0Nj"
      },
      "outputs": [],
      "source": [
        "l_cols_stan = list(x_data_pd_stan.columns)\n",
        "\n",
        "l_cols_stan = l_cols_stan[0:len(l_cols_stan)-1]\n",
        "\n",
        "x_train_pd = pd.DataFrame(x_train,columns=l_cols_stan[:len(l_cols_stan)-1])\n",
        "\n",
        "x_train_pd[\"label\"] = y_train\n",
        "\n",
        "x_train_pd.to_csv(\"Training_data.csv\")\n",
        "\n",
        "x_test_pd = pd.DataFrame(x_test_1,columns=l_cols_stan[:len(l_cols_stan)-1])\n",
        "\n",
        "x_test_pd[\"label\"] = y_test_1\n",
        "\n",
        "x_test_pd.to_csv(\"Testing_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSz361FW_DUq"
      },
      "source": [
        "**Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlM5FHi1_UNh"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN7uxtRFGd5f"
      },
      "outputs": [],
      "source": [
        "model_lr = LogisticRegression(random_state=0,max_iter=1000).fit(x_train,y_train)\n",
        "y_pred_lr=model_lr.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy is:-\",model_lr.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_lr.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLzaTvCyY1Bi"
      },
      "outputs": [],
      "source": [
        "temp_arr=model_lr.coef_\n",
        "print(temp_arr)\n",
        "temp_arr.sort()\n",
        "temp_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mh26W54PJrhb"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_lr, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x20ps2sRIyiB"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_lr,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2rbVwgnKkIV"
      },
      "outputs": [],
      "source": [
        "probs = model_lr.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt2QNVEeLKBw"
      },
      "source": [
        "**Gaussian Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Le5lB1bLat4"
      },
      "outputs": [],
      "source": [
        "model_nb = GaussianNB().fit(x_train,y_train)\n",
        "y_pred_nb=model_nb.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy is:-\",model_nb.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_nb.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYNnduU6Lat5"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_nb, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPg_jgqULat5"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_nb,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWijAPCxLat5"
      },
      "outputs": [],
      "source": [
        "probs = model_nb.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1A6N3MZ6H"
      },
      "source": [
        "**Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x688AK4BdlCX"
      },
      "outputs": [],
      "source": [
        "acc=[]\n",
        "for i in range(20):\n",
        "  model = DecisionTreeClassifier(max_depth=i+1).fit(x_train,y_train)\n",
        "  acc.append(model.score(x_val,y_val))\n",
        "\n",
        "plt.plot(acc)\n",
        "plt.show()\n",
        "best_depth=np.argmax(acc)+1\n",
        "print(best_depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCmhD6ENNcYa"
      },
      "outputs": [],
      "source": [
        "model_dc = DecisionTreeClassifier(max_depth=best_depth).fit(x_train,y_train)\n",
        "y_pred_dc=model_dc.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy is:-\",model_dc.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_dc.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frZ2VpgeNcYa"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_dc, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvXc-alqNcYb"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_dc,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLiRzl1hNcYb"
      },
      "outputs": [],
      "source": [
        "probs = model_dc.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OozVhvQOFNi"
      },
      "source": [
        "**Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKBTdkvheUnj"
      },
      "outputs": [],
      "source": [
        "acc=[]\n",
        "for i in range(20):\n",
        "  model = RandomForestClassifier(max_depth=i+1,n_estimators=1000).fit(x_train,y_train)\n",
        "  acc.append(model.score(x_val,y_val))\n",
        "\n",
        "plt.plot(acc)\n",
        "plt.show()\n",
        "best_depth=np.argmax(acc)+1\n",
        "print(best_depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqoC8_iOOaEm"
      },
      "outputs": [],
      "source": [
        "model_rfc = RandomForestClassifier(max_depth=best_depth,n_estimators=1000,random_state=0).fit(x_train,y_train)\n",
        "y_pred_rfc=model_rfc.predict(x_test)\n",
        "\n",
        "\n",
        "print(\"Training Accuracy is:-\",model_rfc.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_rfc.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi_Hw-BUOaEn"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_rfc, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vga9ryulOaEn"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_rfc,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWr7uNcsOaEn"
      },
      "outputs": [],
      "source": [
        "probs = model_rfc.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3unIt6YPDMj"
      },
      "source": [
        "**XGBoost Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPd0Tpyqeros"
      },
      "outputs": [],
      "source": [
        "acc=[]\n",
        "for i in range(10):\n",
        "  model = XGBClassifier(max_depth=i+1).fit(x_train,y_train)\n",
        "  acc.append(model.score(x_val,y_val))\n",
        "\n",
        "plt.plot(acc)\n",
        "plt.show()\n",
        "best_depth=np.argmax(acc)+1\n",
        "print(best_depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-hGCwVePJJt"
      },
      "outputs": [],
      "source": [
        "model_xgb = XGBClassifier(max_depth=best_depth,random_state=0).fit(x_train,y_train)\n",
        "y_pred_xgb=model_xgb.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy is:-\",model_xgb.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_xgb.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnRXtgBOPJJu"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_xgb, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APAcsB0TPJJu"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_xgb,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwBSGp5uPJJv"
      },
      "outputs": [],
      "source": [
        "probs = model_xgb.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxCbzF5qEs3j"
      },
      "source": [
        "**Gaussian Process Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1Wuq8N2P1a3"
      },
      "outputs": [],
      "source": [
        "lbound = 1e-5\n",
        "rbound = 1e5\n",
        "\n",
        "n_restarts = 50\n",
        "\n",
        "n_features = len(x_train[0])\n",
        "\n",
        "kernel=C(1.0, (lbound,rbound)) * RBF(n_features*[n_features], (lbound,rbound))  + WhiteKernel()\n",
        "\n",
        "model_gpc = GaussianProcessClassifier().fit(x_train,y_train)\n",
        "y_pred_gpc=model_gpc.predict(x_test)\n",
        "\n",
        "print(\"Classification Accuracy is:-\",model_gpc.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbkTEIOcP1a3"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_gpc, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EGnmaBKP1a3"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_gpc,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRWv5gLNP1a4"
      },
      "outputs": [],
      "source": [
        "probs = model_gpc.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NE4w-JPSX9n"
      },
      "source": [
        "**KNN Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah3Y46fbfth3"
      },
      "outputs": [],
      "source": [
        "acc=[]\n",
        "for i in range(30):\n",
        "  model = KNeighborsClassifier(n_neighbors=i+1).fit(x_train,y_train)\n",
        "  acc.append(model.score(x_val,y_val))\n",
        "\n",
        "plt.plot(acc)\n",
        "plt.show()\n",
        "best_n=np.argmax(acc)+1\n",
        "print(best_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4drDfmbLSdYM"
      },
      "outputs": [],
      "source": [
        "model_knn = KNeighborsClassifier(n_neighbors=best_n).fit(x_train,y_train)\n",
        "y_pred_knn=model_knn.predict(x_test)\n",
        "\n",
        "print(\"Classification Accuracy is:-\",model_knn.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORN007CKSdYM"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_knn, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACF99FKrSdYM"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_knn,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiqRLrwdSdYM"
      },
      "outputs": [],
      "source": [
        "probs = model_knn.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_jdVkLhS5ga"
      },
      "source": [
        "**Neural Network Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF7fz0N9NLuY"
      },
      "outputs": [],
      "source": [
        "#For the Standardised data\n",
        "acc1=[]\n",
        "for i in range(1):\n",
        "  model = MLPClassifier(random_state=1,hidden_layer_sizes=[i+1], max_iter=3000)\n",
        "  model.fit(x_train,y_train.ravel())\n",
        "  acc1.append(model.score(x_val,y_val.ravel()))\n",
        "\n",
        "plt.plot(acc1)\n",
        "plt.show()\n",
        "\n",
        "best_hidden1=np.argmax(acc1)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqzoA9VLNLuZ"
      },
      "outputs": [],
      "source": [
        "model_nn = MLPClassifier(random_state=1,hidden_layer_sizes=[best_hidden1], max_iter=3000).fit(x_train,y_train)\n",
        "y_pred_nn=model_nn.predict(x_test)\n",
        "\n",
        "print(best_hidden1)\n",
        "\n",
        "print(\"Accuracy on the training data is:-\",model_nn.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_nn.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgN_Zb-TNLuZ"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_nn, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk7-79CbNLuZ"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_nn,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwzyM89jNLuZ"
      },
      "outputs": [],
      "source": [
        "probs = model_nn.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-tRgLFRh41W"
      },
      "source": [
        "**LDA Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PNJfjqjh9Kc"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "model_lda =LinearDiscriminantAnalysis().fit(x_train,y_train)\n",
        "y_pred_lda=model_lda.predict(x_test)\n",
        "\n",
        "print(\"Classification Accuracy is:-\",model_lda.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZV9XddEh9Kd"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_lda, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXALN-tCh9Kd"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_lda,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qc7UIh5h9Kd"
      },
      "outputs": [],
      "source": [
        "probs = model_lda.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPvTkEeCytig"
      },
      "source": [
        "**Support Vector Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-wPTZc2y2ur"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model_svc = SVC(probability=True,kernel='rbf').fit(x_train,y_train)\n",
        "y_pred_svc=model_svc.predict(x_test)\n",
        "\n",
        "print(\"Classification Accuracy is:-\",model_svc.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCL28v9zy2ur"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test, y_pred_svc, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLvR1dCFy2ur"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_svc,y_test)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKjc8lXSy2ur"
      },
      "outputs": [],
      "source": [
        "probs = model_svc.predict_proba(x_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HignqKFVwgP2"
      },
      "source": [
        "**Sk-learn Neural Network Optimisation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRr3XA0nwkAv"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "  n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
        "\n",
        "  temp_neurons=[]\n",
        "\n",
        "  for i in range(n_layers):\n",
        "    temp_neurons.append(trial.suggest_int(str(i), 1, 1000))\n",
        "\n",
        "\n",
        "  model = MLPClassifier(random_state=1,hidden_layer_sizes=temp_neurons, max_iter=3000)\n",
        "\n",
        "  #Training the Model\n",
        "\n",
        "  model.fit(x_train,y_train.ravel())\n",
        "\n",
        "  y_pred = model.predict(x_val)\n",
        "\n",
        "  v0 = metrics.f1_score(y_val, y_pred, average='micro')\n",
        "\n",
        "  return v0\n",
        "\n",
        "\n",
        "study = optuna.create_study(directions=[\"maximize\"])\n",
        "study.optimize(objective, n_trials=500)\n",
        "\n",
        "print(study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj3BAMwlT_N9"
      },
      "outputs": [],
      "source": [
        "print(np.array(list(study.best_params.values()))[1:].astype(int))\n",
        "temp_arrr=np.array(list(study.best_params.values()))[1:].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3EpaiBi_BJP"
      },
      "outputs": [],
      "source": [
        "model_nn = MLPClassifier(random_state=1,hidden_layer_sizes=temp_arrr, max_iter=3000).fit(x_train,y_train)\n",
        "y_pred_nn=model_nn.predict(x_test_1)\n",
        "\n",
        "print(\"Accuracy on the training data is:-\",model_nn.score(x_train,y_train))\n",
        "print(\"Classification Accuracy is:-\",model_nn.score(x_test_1,y_test_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2w-UXI_m_BJQ"
      },
      "outputs": [],
      "source": [
        "target_names = ['Adenocarcinoma','Squamous']\n",
        "print(classification_report(y_test_1, y_pred_nn, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLN124yY_BJQ"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_nn,y_test_1)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dlj8vh0Q_BJQ"
      },
      "outputs": [],
      "source": [
        "probs = model_nn.predict_proba(x_test_1)\n",
        "preds = probs[:,1]\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test_1, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDedj4bsdGsL"
      },
      "source": [
        "**Pytorch Neural Network Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-yPgYOkNLuc"
      },
      "outputs": [],
      "source": [
        "x_data=x_train\n",
        "x_train_T = torch.Tensor(x_train)\n",
        "y_train=y_train.reshape((-1,1))\n",
        "y_train_T = torch.Tensor(y_train.astype(int))\n",
        "\n",
        "train_data = torch.utils.data.TensorDataset(x_train_T,y_train_T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paRcAOjHCeCB"
      },
      "source": [
        "**Validation Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX6EhGzCCgFs"
      },
      "outputs": [],
      "source": [
        "x_val_T = torch.Tensor(x_val)\n",
        "y_val=y_val.reshape((-1,1))\n",
        "y_val_T = torch.Tensor(y_val.astype(int))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt4B_98lNLuc"
      },
      "source": [
        "**Testing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm94hBcJNLuc"
      },
      "outputs": [],
      "source": [
        "x_test_T = torch.Tensor(x_test_1)\n",
        "y_test_1=y_test_1.reshape((-1,1))\n",
        "y_test_T = torch.Tensor(y_test_1.astype(int))\n",
        "\n",
        "test_data = torch.utils.data.TensorDataset(x_test_T,y_test_T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPLVZ1XbNLuc"
      },
      "outputs": [],
      "source": [
        "train_data_load=torch.utils.data.DataLoader(train_data,batch_size=16,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ4pJJm7NLud"
      },
      "source": [
        "**Model Building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQMg-cpCx5TT"
      },
      "source": [
        "**Two Layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPYaZrzENLud"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Net2(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, size_hidden_1, size_hidden_2, n_output):\n",
        "      super(Net2, self).__init__()\n",
        "\n",
        "      self.hidden_layer_1 = torch.nn.Linear(num_inputs, size_hidden_1)\n",
        "      self.activation_hidden_layer_1 = torch.nn.ReLU()\n",
        "\n",
        "      self.hidden_layer_2 = torch.nn.Linear(size_hidden_1, size_hidden_2)\n",
        "      self.activation_hidden_layer_2 = torch.nn.ReLU()\n",
        "\n",
        "      self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "      self.output_layer = torch.nn.Linear(size_hidden_2, n_output)\n",
        "      self.activation_output_layer = torch.nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      temp_x1 = self.activation_hidden_layer_1(self.hidden_layer_1(x))\n",
        "\n",
        "      temp_x2 = self.activation_hidden_layer_2(self.hidden_layer_2(temp_x1))\n",
        "\n",
        "      temp_x3 = self.dropout(temp_x2)\n",
        "\n",
        "      temp_x4 = self.activation_output_layer(self.output_layer(temp_x3))\n",
        "\n",
        "      return temp_x4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPG2k7KmyGOq"
      },
      "source": [
        "**Three Layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc_9RdmNrysG"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Net1(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, size_hidden_1, size_hidden_2,size_hidden_3 , n_output):\n",
        "      super(Net1, self).__init__()\n",
        "\n",
        "      self.hidden_layer_1 = torch.nn.Linear(num_inputs, size_hidden_1)\n",
        "      self.activation_hidden_layer_1 = torch.nn.ReLU()\n",
        "\n",
        "      self.hidden_layer_2 = torch.nn.Linear(size_hidden_1, size_hidden_2)\n",
        "      self.activation_hidden_layer_2 = torch.nn.ReLU()\n",
        "\n",
        "      self.hidden_layer_3 = torch.nn.Linear(size_hidden_2, size_hidden_3)\n",
        "      self.activation_hidden_layer_3 = torch.nn.ReLU()\n",
        "\n",
        "      self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "      self.output_layer = torch.nn.Linear(size_hidden_3, n_output)\n",
        "      self.activation_output_layer = torch.nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      temp_x1 = self.activation_hidden_layer_1(self.hidden_layer_1(x))\n",
        "\n",
        "      temp_x2 = self.activation_hidden_layer_2(self.hidden_layer_2(temp_x1))\n",
        "\n",
        "      temp_x3 = self.activation_hidden_layer_3(self.hidden_layer_3(temp_x2))\n",
        "\n",
        "      temp_x4 = self.dropout(temp_x3)\n",
        "\n",
        "      temp_x5 = self.activation_output_layer(self.output_layer(temp_x4))\n",
        "\n",
        "      return temp_x5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpzq1-QvNwVS"
      },
      "source": [
        "**Four Layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsjs3KKKNyno"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Net3(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, size_hidden_1, size_hidden_2,size_hidden_3 ,size_hidden_4 , n_output):\n",
        "      super(Net3, self).__init__()\n",
        "\n",
        "      self.hidden_layer_1 = torch.nn.Linear(num_inputs, size_hidden_1)\n",
        "      self.activation_hidden_layer_1 = torch.nn.ReLU()\n",
        "\n",
        "      self.hidden_layer_2 = torch.nn.Linear(size_hidden_1, size_hidden_2)\n",
        "      self.activation_hidden_layer_2 = torch.nn.ReLU()\n",
        "\n",
        "      self.hidden_layer_3 = torch.nn.Linear(size_hidden_2, size_hidden_3)\n",
        "      self.activation_hidden_layer_3 = torch.nn.ReLU()\n",
        "\n",
        "      self.hidden_layer_4 = torch.nn.Linear(size_hidden_3, size_hidden_4)\n",
        "      self.activation_hidden_layer_4 = torch.nn.ReLU()\n",
        "\n",
        "      self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "      self.output_layer = torch.nn.Linear(size_hidden_4, n_output)\n",
        "      self.activation_output_layer = torch.nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      temp_x1 = self.activation_hidden_layer_1(self.hidden_layer_1(x))\n",
        "\n",
        "      temp_x2 = self.activation_hidden_layer_2(self.hidden_layer_2(temp_x1))\n",
        "\n",
        "      temp_x3 = self.activation_hidden_layer_3(self.hidden_layer_3(temp_x2))\n",
        "\n",
        "      temp_x4 = self.activation_hidden_layer_4(self.hidden_layer_4(temp_x3))\n",
        "\n",
        "      temp_x5 = self.dropout(temp_x4)\n",
        "\n",
        "      temp_x6 = self.activation_output_layer(self.output_layer(temp_x5))\n",
        "\n",
        "      return temp_x6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MpyC0zQlLCV"
      },
      "source": [
        "**Hyperparameter Optimisation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU6rYyMwlNPf"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "  x = trial.suggest_int(\"x\", 1, 1000)\n",
        "  y = trial.suggest_int(\"y\", 1, 1000)\n",
        "  z = trial.suggest_int(\"z\", 1, 1000)\n",
        "\n",
        "  train_data_load=torch.utils.data.DataLoader(train_data,batch_size=16,shuffle=True)\n",
        "\n",
        "  model1 = Net1(len(x_data[0]),x,y,z,1)\n",
        "\n",
        "\n",
        "  #Training the Model\n",
        "  optimiser=optim.Adam(model1.parameters(),lr=0.001)\n",
        "\n",
        "  #Loss function\n",
        "  loss=torch.nn.BCELoss()\n",
        "\n",
        "  num_epoch=100\n",
        "\n",
        "  for i in range(num_epoch):\n",
        "    losses=[]\n",
        "    for batch in train_data_load:\n",
        "      x,y=batch\n",
        "\n",
        "      b=len(x)\n",
        "      x=x.reshape(b,-1)\n",
        "\n",
        "      l=model1(x)\n",
        "\n",
        "      J=loss(l,y)\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "\n",
        "      J.backward()\n",
        "\n",
        "      optimiser.step()\n",
        "\n",
        "  y_pred = model1(x_val_T)\n",
        "\n",
        "  y_pred_np = y_pred.detach().numpy()\n",
        "\n",
        "  y_val_np = y_val_T.numpy()\n",
        "\n",
        "  y_temp_pred =[1 if value >= 0.5 else 0 for value in y_pred_np]\n",
        "\n",
        "  print(y_temp_pred)\n",
        "\n",
        "  v0 = metrics.f1_score(y_val_np, y_temp_pred, average='micro')\n",
        "\n",
        "  return v0\n",
        "\n",
        "\n",
        "study = optuna.create_study(directions=[\"maximize\"])\n",
        "study.optimize(objective, n_trials=250)\n",
        "\n",
        "print(study.best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6mKOomCygzw"
      },
      "outputs": [],
      "source": [
        "temp_neuron_size = list(study.best_params.values())\n",
        "\n",
        "model1=Net1(len(x_train[0]),temp_neuron_size[0],temp_neuron_size[1],temp_neuron_size[2],1)\n",
        "\n",
        "print(model1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnBR10xcSma-"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdZkCiB3Sma-"
      },
      "outputs": [],
      "source": [
        "#optimiser\n",
        "optimiser=optim.Adam(model1.parameters(),lr=0.0005)\n",
        "# optimiser=optim.SGD(model.parameters(),lr=0.0005,momentum=0.5)\n",
        "\n",
        "#Loss function\n",
        "loss=torch.nn.BCELoss()\n",
        "\n",
        "# loss=torch.nn.L1Loss()\n",
        "\n",
        "num_epoch=100\n",
        "loss_epoch_train=[]\n",
        "\n",
        "loss_epoch_val=[]\n",
        "\n",
        "for i in range(num_epoch):\n",
        "  losses=[]\n",
        "  for batch in train_data_load:\n",
        "    x,y=batch\n",
        "\n",
        "    b=len(x)\n",
        "    x=x.reshape(b,-1)\n",
        "\n",
        "    l=model1(x)\n",
        "\n",
        "    J=loss(l,y)\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    J.backward()\n",
        "\n",
        "    optimiser.step()\n",
        "\n",
        "    losses.append(J.item())\n",
        "\n",
        "  y_pred_T=model1(x_val_T)\n",
        "\n",
        "  J1=loss(y_val_T,y_pred_T)\n",
        "  loss_epoch_val.append(J1.item())\n",
        "\n",
        "  print(\"Training Loss for epoch \"+str(i+1)+\":\",torch.tensor(losses).mean().item())\n",
        "  print(\"Validation Loss for epoch \"+str(i+1)+\":\",J1.item())\n",
        "  loss_epoch_train.append(torch.tensor(losses).mean().item())\n",
        "\n",
        "\n",
        "plt.plot(loss_epoch_train,label=\"Train Data\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Mean Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_epoch_val,label=\"Val Data\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Mean Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKAF0HRZSma-"
      },
      "outputs": [],
      "source": [
        "y_pred=model1(x_test_T)\n",
        "J=loss(y_pred.reshape(1,-1),y_test_T.reshape(1,-1))\n",
        "\n",
        "print(J.item())\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "y_pred=y_pred.detach().numpy()\n",
        "y_pred_temp=[]\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "  if (y_pred[i]>=0.5):\n",
        "    y_pred_temp.append(1)\n",
        "  else:\n",
        "    y_pred_temp.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3KYRx07Sma-"
      },
      "outputs": [],
      "source": [
        "y_test_temp=y_test_T.detach().numpy().astype(int)\n",
        "\n",
        "target_names = ['class 0', 'class 1']\n",
        "\n",
        "print(classification_report(y_test_temp, y_pred_temp, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_dXl1SlSma_"
      },
      "outputs": [],
      "source": [
        "print(list(y_test_temp.ravel()))\n",
        "print(y_pred_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhgkjDVCSma_"
      },
      "outputs": [],
      "source": [
        "class_0=[]\n",
        "class_1=[]\n",
        "y_pred=y_pred.ravel()\n",
        "for i in range(len(y_pred_temp)):\n",
        "  if (y_test_temp[i]==0):\n",
        "    class_0.append(y_pred[i])\n",
        "  else:\n",
        "    class_1.append(y_pred[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsJLPrYkSma_"
      },
      "outputs": [],
      "source": [
        "plt.hist(class_0,color=\"red\",alpha=0.5)\n",
        "plt.hist(class_1,color=\"blue\",alpha=0.5)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSkKiI1BSma_"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_temp,y_test_temp)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrPq7VFt8U2x"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_pred_temp)):\n",
        "  if (y_pred_temp[i]==0 and y_pred_temp[i]!=y_test_temp[i]):\n",
        "    print(sample_id_test_1[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNReZJ-N8Xzr"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_pred_temp)):\n",
        "  if (y_pred_temp[i]==1 and y_pred_temp[i]!=y_test_temp[i]):\n",
        "    print(sample_id_test_1[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho-tr_dOzg7j"
      },
      "outputs": [],
      "source": [
        "preds = y_pred\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test_temp, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "om9wcx-OsYhA"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "  x = trial.suggest_int(\"x\", 1, 1000)\n",
        "  y = trial.suggest_int(\"y\", 1, 1000)\n",
        "\n",
        "  train_data_load=torch.utils.data.DataLoader(train_data,batch_size=16,shuffle=True)\n",
        "\n",
        "  model2 = Net2(len(x_data[0]),x,y,1)\n",
        "\n",
        "\n",
        "  #Training the Model\n",
        "\n",
        "  optimiser=optim.Adam(model2.parameters(),lr=0.001)\n",
        "\n",
        "  #Loss function\n",
        "  loss=torch.nn.BCELoss()\n",
        "\n",
        "  num_epoch=100\n",
        "\n",
        "  for i in range(num_epoch):\n",
        "    losses=[]\n",
        "    for batch in train_data_load:\n",
        "      x,y=batch\n",
        "\n",
        "      b=len(x)\n",
        "      x=x.reshape(b,-1)\n",
        "\n",
        "      l=model2(x)\n",
        "\n",
        "      J=loss(l,y)\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "\n",
        "      J.backward()\n",
        "\n",
        "      optimiser.step()\n",
        "\n",
        "\n",
        "  y_pred = model2(x_val_T)\n",
        "\n",
        "  y_pred_np = y_pred.detach().numpy()\n",
        "\n",
        "  y_val_np = y_val_T.numpy()\n",
        "\n",
        "  y_temp_pred = y_pred_np>0.5\n",
        "\n",
        "  v0 = metrics.f1_score(y_val_np, y_temp_pred, average='micro')\n",
        "\n",
        "  return v0\n",
        "\n",
        "\n",
        "study = optuna.create_study(directions=[\"maximize\"])\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "print(study.best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W82SbCQmz4kc"
      },
      "outputs": [],
      "source": [
        "temp_neuron_size = list(study.best_params.values())\n",
        "\n",
        "model2=Net2(len(x_train[0]),temp_neuron_size[0],temp_neuron_size[1],1)\n",
        "\n",
        "print(model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aksuatgDNLug"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqw4RmrSNLug"
      },
      "outputs": [],
      "source": [
        "#optimiser\n",
        "optimiser=optim.Adam(model2.parameters(),lr=0.0005)\n",
        "# optimiser=optim.SGD(model.parameters(),lr=0.0005,momentum=0.5)\n",
        "\n",
        "#Loss function\n",
        "loss=torch.nn.BCELoss()\n",
        "\n",
        "num_epoch=100\n",
        "loss_epoch_train=[]\n",
        "\n",
        "loss_epoch_val=[]\n",
        "\n",
        "for i in range(num_epoch):\n",
        "  losses=[]\n",
        "  for batch in train_data_load:\n",
        "    x,y=batch\n",
        "\n",
        "    b=len(x)\n",
        "    x=x.reshape(b,-1)\n",
        "\n",
        "    l=model2(x)\n",
        "\n",
        "    J=loss(l,y)\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    J.backward()\n",
        "\n",
        "    optimiser.step()\n",
        "\n",
        "    losses.append(J.item())\n",
        "\n",
        "  y_pred_T=model2(x_val_T)\n",
        "\n",
        "  J1=loss(y_val_T,y_pred_T)\n",
        "  loss_epoch_val.append(J1.item())\n",
        "\n",
        "  print(\"Training Loss for epoch \"+str(i+1)+\":\",torch.tensor(losses).mean().item())\n",
        "  print(\"Validation Loss for epoch \"+str(i+1)+\":\",J1.item())\n",
        "  loss_epoch_train.append(torch.tensor(losses).mean().item())\n",
        "\n",
        "\n",
        "plt.plot(loss_epoch_train,label=\"Train Data\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Mean Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_epoch_val,label=\"Val Data\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Mean Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_AaU5U2NLug"
      },
      "outputs": [],
      "source": [
        "y_pred=model2(x_test_T)\n",
        "J=loss(y_pred.reshape(1,-1),y_test_T.reshape(1,-1))\n",
        "\n",
        "print(J.item())\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "y_pred=y_pred.detach().numpy()\n",
        "y_pred_temp=[]\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "  if (y_pred[i]>0.4):\n",
        "    y_pred_temp.append(1)\n",
        "  else:\n",
        "    y_pred_temp.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YPehnnINLug"
      },
      "outputs": [],
      "source": [
        "y_test_temp=y_test_T.detach().numpy().astype(int)\n",
        "\n",
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(y_test_temp, y_pred_temp, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzso3SvmQ2Tn"
      },
      "outputs": [],
      "source": [
        "print(list(y_test_temp.ravel()))\n",
        "print(y_pred_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ej2wUcnKiD4"
      },
      "outputs": [],
      "source": [
        "class_0=[]\n",
        "class_1=[]\n",
        "y_pred=y_pred.ravel()\n",
        "for i in range(len(y_pred_temp)):\n",
        "  if (y_test_temp[i]==0):\n",
        "    class_0.append(y_pred[i])\n",
        "  else:\n",
        "    class_1.append(y_pred[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ8mX4QrLIQU"
      },
      "outputs": [],
      "source": [
        "plt.hist(class_0,color=\"red\",alpha=0.5)\n",
        "plt.hist(class_1,color=\"blue\",alpha=0.5)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRbmQ7MgNLuh"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_temp,y_test_temp)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZyjQBEbV-GF"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_pred_temp)):\n",
        "  if (y_pred_temp[i]==0 and y_pred_temp[i]!=y_test_temp[i]):\n",
        "    print(sample_id_test_1[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HLuitxOV-Y6"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_pred_temp)):\n",
        "  if (y_pred_temp[i]==1 and y_pred_temp[i]!=y_test_temp[i]):\n",
        "    print(sample_id_test_1[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOHgRb-20EhL"
      },
      "outputs": [],
      "source": [
        "preds = y_pred\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test_temp, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWlr0MvqOLCB"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "  x = trial.suggest_int(\"x\", 1, 1000)\n",
        "  y = trial.suggest_int(\"y\", 1, 1000)\n",
        "  z = trial.suggest_int(\"z\", 1, 1000)\n",
        "  a = trial.suggest_int(\"a\", 1, 1000)\n",
        "\n",
        "  train_data_load=torch.utils.data.DataLoader(train_data,batch_size=16,shuffle=True)\n",
        "\n",
        "  model3 = Net3(len(x_data[0]),x,y,z,a,1)\n",
        "\n",
        "\n",
        "  #Training the Model\n",
        "  optimiser=optim.Adam(model3.parameters(),lr=0.001)\n",
        "\n",
        "  #Loss function\n",
        "  loss=torch.nn.BCELoss()\n",
        "\n",
        "  num_epoch=100\n",
        "\n",
        "  for i in range(num_epoch):\n",
        "    losses=[]\n",
        "    for batch in train_data_load:\n",
        "      x,y=batch\n",
        "\n",
        "      b=len(x)\n",
        "      x=x.reshape(b,-1)\n",
        "\n",
        "      l=model3(x)\n",
        "\n",
        "      J=loss(l,y)\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "\n",
        "      J.backward()\n",
        "\n",
        "      optimiser.step()\n",
        "\n",
        "  y_pred = model3(x_val_T)\n",
        "\n",
        "  y_pred_np = y_pred.detach().numpy()\n",
        "\n",
        "  y_val_np = y_val_T.numpy()\n",
        "\n",
        "  y_temp_pred =[1 if value >= 0.5 else 0 for value in y_pred_np]\n",
        "\n",
        "  print(y_temp_pred)\n",
        "\n",
        "  v0 = metrics.f1_score(y_val_np, y_temp_pred, average='micro')\n",
        "\n",
        "  return v0\n",
        "\n",
        "\n",
        "study = optuna.create_study(directions=[\"maximize\"])\n",
        "study.optimize(objective, n_trials=250)\n",
        "\n",
        "print(study.best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9242foHOLCB"
      },
      "outputs": [],
      "source": [
        "temp_neuron_size = list(study.best_params.values())\n",
        "\n",
        "model1=Net3(len(x_train[0]),temp_neuron_size[0],temp_neuron_size[1],temp_neuron_size[2],temp_neuron_size[3],1)\n",
        "\n",
        "print(model1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmeVvLRiOLCB"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mjoxbIZOLCB"
      },
      "outputs": [],
      "source": [
        "#optimiser\n",
        "optimiser=optim.Adam(model1.parameters(),lr=0.0005)\n",
        "# optimiser=optim.SGD(model.parameters(),lr=0.0005,momentum=0.5)\n",
        "\n",
        "#Loss function\n",
        "loss=torch.nn.BCELoss()\n",
        "\n",
        "num_epoch=100\n",
        "loss_epoch_train=[]\n",
        "\n",
        "loss_epoch_val=[]\n",
        "\n",
        "for i in range(num_epoch):\n",
        "  losses=[]\n",
        "  for batch in train_data_load:\n",
        "    x,y=batch\n",
        "\n",
        "    b=len(x)\n",
        "    x=x.reshape(b,-1)\n",
        "\n",
        "    l=model1(x)\n",
        "\n",
        "    J=loss(l,y)\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    J.backward()\n",
        "\n",
        "    optimiser.step()\n",
        "\n",
        "    losses.append(J.item())\n",
        "\n",
        "  y_pred_T=model1(x_val_T)\n",
        "\n",
        "  J1=loss(y_pred_T,y_val_T)\n",
        "  loss_epoch_val.append(J1.item())\n",
        "\n",
        "  print(\"Training Loss for epoch \"+str(i+1)+\":\",torch.tensor(losses).mean().item())\n",
        "  print(\"Validation Loss for epoch \"+str(i+1)+\":\",J1.item())\n",
        "  loss_epoch_train.append(torch.tensor(losses).mean().item())\n",
        "\n",
        "\n",
        "plt.plot(loss_epoch_train,label=\"Train Data\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Mean Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(loss_epoch_val,label=\"Val Data\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Mean Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO0bx0VuOLCC"
      },
      "outputs": [],
      "source": [
        "y_pred=model1(x_test_T)\n",
        "J=loss(y_pred.reshape(1,-1),y_test_T.reshape(1,-1))\n",
        "\n",
        "print(J.item())\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "y_pred=y_pred.detach().numpy()\n",
        "y_pred_temp=[]\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "  if (y_pred[i]>=0.5):\n",
        "    y_pred_temp.append(1)\n",
        "  else:\n",
        "    y_pred_temp.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_CftPx3OLCC"
      },
      "outputs": [],
      "source": [
        "y_test_temp=y_test_T.detach().numpy().astype(int)\n",
        "\n",
        "target_names = ['class 0', 'class 1']\n",
        "\n",
        "print(classification_report(y_test_temp, y_pred_temp, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaX-3xJAOLCC"
      },
      "outputs": [],
      "source": [
        "print(list(y_test_temp.ravel()))\n",
        "print(y_pred_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7eFp-VNOLCC"
      },
      "outputs": [],
      "source": [
        "class_0=[]\n",
        "class_1=[]\n",
        "y_pred=y_pred.ravel()\n",
        "for i in range(len(y_pred_temp)):\n",
        "  if (y_test_temp[i]==0):\n",
        "    class_0.append(y_pred[i])\n",
        "  else:\n",
        "    class_1.append(y_pred[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K66p4JXdOLCD"
      },
      "outputs": [],
      "source": [
        "plt.hist(class_0,color=\"red\",alpha=0.5)\n",
        "plt.hist(class_1,color=\"blue\",alpha=0.5)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l4NY-giOLCD"
      },
      "outputs": [],
      "source": [
        "dat_lr=confusion_matrix(y_pred_temp,y_test_temp)\n",
        "sns.heatmap(dat_lr,annot=True,xticklabels=['Adenocarcinoma','Squamous'],\n",
        "            yticklabels=['Adenocarcinoma','Squamous'])\n",
        "plt.title(\"Standardised Data\")\n",
        "plt.ylabel('Prediction',fontsize=13)\n",
        "plt.xlabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lif1fY-QQpl2"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_pred_temp)):\n",
        "  if (y_pred_temp[i]==0 and y_pred_temp[i]!=y_test_temp[i]):\n",
        "    print(sample_id_test_1[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4r7sBuqRHXP"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_pred_temp)):\n",
        "  if (y_pred_temp[i]==1 and y_pred_temp[i]!=y_test_temp[i]):\n",
        "    print(sample_id_test_1[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yR5Lp2sOLCD"
      },
      "outputs": [],
      "source": [
        "preds = y_pred\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test_temp, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD0sR6hhh2ot"
      },
      "source": [
        "**Using Basinhoppin**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIB-XJSFh6F6"
      },
      "outputs": [],
      "source": [
        "def scoring_fun(x):\n",
        "  print(x)\n",
        "  model = Net1(len(x_train[0]),int(x[0]*1000),int(x[1]*1000),int(x[2]*1000),1)\n",
        "  optimiser=optim.Adam(model1.parameters(),lr=0.001)\n",
        "\n",
        "  #Loss function\n",
        "  loss=torch.nn.BCELoss()\n",
        "\n",
        "  num_epoch=50\n",
        "\n",
        "  for i in range(num_epoch):\n",
        "    losses=[]\n",
        "    for batch in train_data_load:\n",
        "      x,y=batch\n",
        "\n",
        "      b=len(x)\n",
        "      x=x.reshape(b,-1)\n",
        "\n",
        "      l=model1(x)\n",
        "\n",
        "      J=loss(l,y)\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "\n",
        "      J.backward()\n",
        "\n",
        "      optimiser.step()\n",
        "\n",
        "  y_pred = model1(x_val_T)\n",
        "\n",
        "  y_pred_np = y_pred.detach().numpy()\n",
        "\n",
        "  y_val_np = y_val_T.numpy()\n",
        "\n",
        "  y_temp_pred =[1 if value >= 0.5 else 0 for value in y_pred_np]\n",
        "\n",
        "  print(y_temp_pred)\n",
        "\n",
        "  v0 = metrics.f1_score(y_val_np, y_temp_pred, average='micro')\n",
        "\n",
        "  return -1*v0\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}